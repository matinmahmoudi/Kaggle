{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f0f9e3",
   "metadata": {
    "papermill": {
     "duration": 0.011556,
     "end_time": "2024-05-28T15:50:44.517909",
     "exception": false,
     "start_time": "2024-05-28T15:50:44.506353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸŒ³ Pandas Mastery Series - Advanced\n",
    "\n",
    "Welcome to the Pandas Mastery Series - Advanced! In this notebook, we will explore advanced pandas topics to enhance your data manipulation and analysis skills. This series will cover complex operations and provide practical examples to deepen your understanding of pandas. Let's dive into the advanced techniques!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### 1. **MultiIndex**\n",
    "- Creating MultiIndex\n",
    "- Accessing MultiIndex\n",
    "- Advanced Indexing with MultiIndex\n",
    "\n",
    "### 2. **Advanced GroupBy**\n",
    "- Grouping by Multiple Columns\n",
    "- Custom Aggregations\n",
    "- Grouping with Functions\n",
    "\n",
    "### 3. **Reshaping**\n",
    "- Pivot and Pivot Tables\n",
    "- Stack and Unstack\n",
    "- Melting DataFrames\n",
    "\n",
    "### 4. **Time Series**\n",
    "- Date Range Generation\n",
    "- Time Zone Handling\n",
    "- Time Series Resampling\n",
    "\n",
    "### 5. **Merging, Joining, and Concatenating**\n",
    "- Concatenating DataFrames\n",
    "- Merging on Index\n",
    "- Advanced Joining Techniques\n",
    "\n",
    "### 6. **Window Functions**\n",
    "- Rolling Windows\n",
    "- Expanding Windows\n",
    "- Applying Custom Functions\n",
    "\n",
    "### 7. **Text Data**\n",
    "- String Methods\n",
    "- Regular Expressions\n",
    "- Extracting Information from Text\n",
    "\n",
    "### 8. **Performance and Optimization**\n",
    "- Efficient Data Loading\n",
    "- Memory Usage Reduction\n",
    "- Parallel Processing\n",
    "\n",
    "### 9. **Fun Challenges**\n",
    "- Challenge 1: The MultiIndex Mystery\n",
    "- Challenge 2: The GroupBy Gauntlet\n",
    "- Challenge 3: The Reshaping Riddle\n",
    "- Challenge 4: The Time Series Trial\n",
    "- Challenge 5: The Optimization Obstacle\n",
    "\n",
    "### Ready for the Ultimate Challenge?\n",
    "\n",
    "Once you've completed all the notebooks in the Pandas Mastery Series, you'll be ready to tackle the final challenge: [Pandas Mastery Series - Ultimate Challenge](https://www.kaggle.com/code/matinmahmoudi/pandas-mastery-series-ultimate-challenge). This ultimate challenge will put your pandas skills to the test and ensure you're truly a pandas master.\n",
    "\n",
    "Let's get started and become pandas advanced masters!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b203f5",
   "metadata": {
    "papermill": {
     "duration": 0.009759,
     "end_time": "2024-05-28T15:50:44.538131",
     "exception": false,
     "start_time": "2024-05-28T15:50:44.528372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. MultiIndex\n",
    "\n",
    "MultiIndex (also known as hierarchical indexing) is an advanced indexing technique that allows for multiple levels of indexing within a pandas DataFrame or Series. This feature enables more complex data analysis and manipulation.\n",
    "\n",
    "### Creating MultiIndex\n",
    "MultiIndex can be created from arrays, lists, or tuples. You can also set an existing DataFrame's index to be a MultiIndex.\n",
    "\n",
    "### Accessing MultiIndex\n",
    "Accessing data in a MultiIndex DataFrame or Series involves using a combination of levels and labels.\n",
    "\n",
    "### Advanced Indexing with MultiIndex\n",
    "Advanced indexing techniques, such as slicing and indexing with multiple levels, can be performed on MultiIndex objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cca76d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:44.560253Z",
     "iopub.status.busy": "2024-05-28T15:50:44.559783Z",
     "iopub.status.idle": "2024-05-28T15:50:45.548234Z",
     "shell.execute_reply": "2024-05-28T15:50:45.547146Z"
    },
    "papermill": {
     "duration": 1.003261,
     "end_time": "2024-05-28T15:50:45.551437",
     "exception": false,
     "start_time": "2024-05-28T15:50:44.548176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex from arrays:\n",
      " MultiIndex([('Hobbit',   'Frodo'),\n",
      "            ('Hobbit',     'Sam'),\n",
      "            ('Wizard', 'Gandalf'),\n",
      "            ( 'Human', 'Aragorn'),\n",
      "            (   'Elf', 'Legolas')],\n",
      "           names=['Race', 'Character'])\n",
      "\n",
      "DataFrame with MultiIndex:\n",
      "                    Age         Role\n",
      "Race   Character                   \n",
      "Hobbit Frodo        50  Ring-bearer\n",
      "       Sam          38     Gardener\n",
      "Wizard Gandalf    2019       Wizard\n",
      "Human  Aragorn      87         King\n",
      "Elf    Legolas    2931       Archer\n",
      "\n",
      "Data for 'Hobbit' race:\n",
      "            Age         Role\n",
      "Character                  \n",
      "Frodo       50  Ring-bearer\n",
      "Sam         38     Gardener\n",
      "\n",
      "Data for 'Gandalf' in 'Wizard' race:\n",
      " Age       2019\n",
      "Role    Wizard\n",
      "Name: (Wizard, Gandalf), dtype: object\n",
      "\n",
      "Data for 'Hobbit' and 'Wizard' races:\n",
      "                    Age         Role\n",
      "Race   Character                   \n",
      "Hobbit Frodo        50  Ring-bearer\n",
      "       Sam          38     Gardener\n",
      "Wizard Gandalf    2019       Wizard\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "arrays = [\n",
    "    ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf'],\n",
    "    ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas']\n",
    "]\n",
    "multi_index = pd.MultiIndex.from_arrays(arrays, names=('Race', 'Character'))\n",
    "print(\"MultiIndex from arrays:\\n\", multi_index)\n",
    "\n",
    "# Creating a DataFrame with MultiIndex\n",
    "data = {\n",
    "    'Age': [50, 38, 2019, 87, 2931],\n",
    "    'Role': ['Ring-bearer', 'Gardener', 'Wizard', 'King', 'Archer']\n",
    "}\n",
    "df_multi = pd.DataFrame(data, index=multi_index)\n",
    "print(\"\\nDataFrame with MultiIndex:\\n\", df_multi)\n",
    "\n",
    "# Accessing MultiIndex\n",
    "# Accessing data for 'Hobbit' race\n",
    "hobbit_data = df_multi.loc['Hobbit']\n",
    "print(\"\\nData for 'Hobbit' race:\\n\", hobbit_data)\n",
    "\n",
    "# Accessing data for 'Gandalf' in 'Wizard' race\n",
    "gandalf_data = df_multi.loc[('Wizard', 'Gandalf')]\n",
    "print(\"\\nData for 'Gandalf' in 'Wizard' race:\\n\", gandalf_data)\n",
    "\n",
    "# Advanced Indexing with MultiIndex\n",
    "# Slicing data for 'Hobbit' and 'Wizard' races\n",
    "hobbit_wizard_data = df_multi.loc[['Hobbit', 'Wizard']]\n",
    "print(\"\\nData for 'Hobbit' and 'Wizard' races:\\n\", hobbit_wizard_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763c288",
   "metadata": {
    "papermill": {
     "duration": 0.010174,
     "end_time": "2024-05-28T15:50:45.572194",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.562020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Advanced GroupBy\n",
    "\n",
    "The GroupBy operation in pandas is powerful for aggregating data. Advanced GroupBy techniques include grouping by multiple columns, custom aggregations, and grouping with functions.\n",
    "\n",
    "### Grouping by Multiple Columns\n",
    "You can group data by more than one column, allowing for more granular analysis.\n",
    "\n",
    "### Custom Aggregations\n",
    "Custom aggregation functions can be applied to grouped data for specific calculations.\n",
    "\n",
    "### Grouping with Functions\n",
    "You can group data using custom functions to define the grouping criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e13a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:45.596354Z",
     "iopub.status.busy": "2024-05-28T15:50:45.595518Z",
     "iopub.status.idle": "2024-05-28T15:50:45.632463Z",
     "shell.execute_reply": "2024-05-28T15:50:45.631631Z"
    },
    "papermill": {
     "duration": 0.052496,
     "end_time": "2024-05-28T15:50:45.635567",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.583071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by Race and Character:\n",
      " Race    Character\n",
      "Dwarf   Gimli         139.0\n",
      "Elf     Legolas      2931.0\n",
      "Hobbit  Frodo          50.0\n",
      "        Merry          37.0\n",
      "        Pippin         29.0\n",
      "        Sam            38.0\n",
      "Human   Aragorn        87.0\n",
      "        Boromir        41.0\n",
      "Wizard  Gandalf      2019.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Custom Aggregations:\n",
      "         count  mean_age  age_range\n",
      "Race                              \n",
      "Dwarf       1     139.0          0\n",
      "Elf         1    2931.0          0\n",
      "Hobbit      4      38.5         21\n",
      "Human       2      64.0         46\n",
      "Wizard      1    2019.0          0\n",
      "\n",
      "Grouped by Age Group:\n",
      "                   Age\n",
      "AgeGroup             \n",
      "Old       1696.333333\n",
      "Young       47.000000\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame for GroupBy operations\n",
    "data = {\n",
    "    'Character': ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas', 'Boromir', 'Gimli', 'Pippin', 'Merry'],\n",
    "    'Race': ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf', 'Human', 'Dwarf', 'Hobbit', 'Hobbit'],\n",
    "    'Age': [50, 38, 2019, 87, 2931, 41, 139, 29, 37]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Grouping by multiple columns\n",
    "grouped_multi = df.groupby(['Race', 'Character'])['Age'].mean()\n",
    "print(\"Grouped by Race and Character:\\n\", grouped_multi)\n",
    "\n",
    "# Custom Aggregations\n",
    "# Define custom aggregation functions\n",
    "def range_agg(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "custom_agg = df.groupby('Race').agg(\n",
    "    count=('Age', 'size'),\n",
    "    mean_age=('Age', 'mean'),\n",
    "    age_range=('Age', range_agg)\n",
    ")\n",
    "print(\"\\nCustom Aggregations:\\n\", custom_agg)\n",
    "\n",
    "# Grouping with Functions\n",
    "# Define a function to group characters into 'Young' and 'Old'\n",
    "def age_group(age):\n",
    "    return 'Young' if age < 100 else 'Old'\n",
    "\n",
    "# Apply the function to the 'Age' column to create a new column 'AgeGroup'\n",
    "df['AgeGroup'] = df['Age'].apply(age_group)\n",
    "\n",
    "# Group by 'AgeGroup' and calculate the mean for numeric columns\n",
    "grouped_func = df.groupby('AgeGroup').mean(numeric_only=True)\n",
    "print(\"\\nGrouped by Age Group:\\n\", grouped_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d847ca6",
   "metadata": {
    "papermill": {
     "duration": 0.010165,
     "end_time": "2024-05-28T15:50:45.656181",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.646016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Reshaping\n",
    "\n",
    "Reshaping data in pandas involves changing the layout of a DataFrame or Series. This can include pivoting, stacking, unstacking, and melting data.\n",
    "\n",
    "### Pivot and Pivot Tables\n",
    "Pivoting involves reshaping data to form a different DataFrame, typically for summary statistics.\n",
    "\n",
    "### Stack and Unstack\n",
    "Stacking involves compressing a level in a MultiIndex to columns, while unstacking involves expanding a level in a MultiIndex to rows.\n",
    "\n",
    "### Melting DataFrames\n",
    "Melting converts a DataFrame from a wide format to a long format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea8c6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:45.679169Z",
     "iopub.status.busy": "2024-05-28T15:50:45.678742Z",
     "iopub.status.idle": "2024-05-28T15:50:45.720444Z",
     "shell.execute_reply": "2024-05-28T15:50:45.719024Z"
    },
    "papermill": {
     "duration": 0.056599,
     "end_time": "2024-05-28T15:50:45.723209",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.666610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table:\n",
      " Role    Archer  Gardener  King  Ring-bearer  Wizard\n",
      "Race                                               \n",
      "Elf     2931.0       NaN   NaN          NaN     NaN\n",
      "Hobbit     NaN      38.0   NaN         50.0     NaN\n",
      "Human      NaN       NaN  87.0          NaN     NaN\n",
      "Wizard     NaN       NaN   NaN          NaN  2019.0\n",
      "\n",
      "Stacked DataFrame:\n",
      " Race    Character      \n",
      "Hobbit  Frodo      Age              50\n",
      "                   Role    Ring-bearer\n",
      "        Sam        Age              38\n",
      "                   Role       Gardener\n",
      "Wizard  Gandalf    Age            2019\n",
      "                   Role         Wizard\n",
      "Human   Aragorn    Age              87\n",
      "                   Role           King\n",
      "Elf     Legolas    Age            2931\n",
      "                   Role         Archer\n",
      "dtype: object\n",
      "\n",
      "Unstacked DataFrame:\n",
      "                    Age         Role\n",
      "Race   Character                   \n",
      "Elf    Legolas    2931       Archer\n",
      "Hobbit Frodo        50  Ring-bearer\n",
      "       Sam          38     Gardener\n",
      "Human  Aragorn      87         King\n",
      "Wizard Gandalf    2019       Wizard\n",
      "\n",
      "Melted DataFrame:\n",
      "    Character Attribute        Value\n",
      "0      Frodo      Race       Hobbit\n",
      "1        Sam      Race       Hobbit\n",
      "2    Gandalf      Race       Wizard\n",
      "3    Aragorn      Race        Human\n",
      "4    Legolas      Race          Elf\n",
      "5      Frodo       Age           50\n",
      "6        Sam       Age           38\n",
      "7    Gandalf       Age         2019\n",
      "8    Aragorn       Age           87\n",
      "9    Legolas       Age         2931\n",
      "10     Frodo      Role  Ring-bearer\n",
      "11       Sam      Role     Gardener\n",
      "12   Gandalf      Role       Wizard\n",
      "13   Aragorn      Role         King\n",
      "14   Legolas      Role       Archer\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Character': ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas'],\n",
    "    'Race': ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf'],\n",
    "    'Age': [50, 38, 2019, 87, 2931],\n",
    "    'Role': ['Ring-bearer', 'Gardener', 'Wizard', 'King', 'Archer']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot Table\n",
    "pivot_table = df.pivot_table(values='Age', index='Race', columns='Role', aggfunc='mean')\n",
    "print(\"Pivot Table:\\n\", pivot_table)\n",
    "\n",
    "# Stack\n",
    "stacked = df.set_index(['Race', 'Character']).stack()\n",
    "print(\"\\nStacked DataFrame:\\n\", stacked)\n",
    "\n",
    "# Unstack\n",
    "unstacked = stacked.unstack()\n",
    "print(\"\\nUnstacked DataFrame:\\n\", unstacked)\n",
    "\n",
    "# Melting\n",
    "melted = pd.melt(df, id_vars=['Character'], value_vars=['Race', 'Age', 'Role'], var_name='Attribute', value_name='Value')\n",
    "print(\"\\nMelted DataFrame:\\n\", melted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081936f8",
   "metadata": {
    "papermill": {
     "duration": 0.011609,
     "end_time": "2024-05-28T15:50:45.745431",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.733822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Time Series\n",
    "\n",
    "Time series data is a sequence of data points recorded over time. pandas provides robust functionality for working with time series data, including creating time series, resampling, shifting, and applying rolling windows.\n",
    "\n",
    "### Date Range Generation\n",
    "Creating sequences of dates using `pd.date_range()` for generating time series indices.\n",
    "\n",
    "### Time Zone Handling\n",
    "Converting time series data to different time zones.\n",
    "\n",
    "### Time Series Resampling\n",
    "Changing the frequency of your time series data using resampling methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b57c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:45.769844Z",
     "iopub.status.busy": "2024-05-28T15:50:45.768541Z",
     "iopub.status.idle": "2024-05-28T15:50:45.856759Z",
     "shell.execute_reply": "2024-05-28T15:50:45.855414Z"
    },
    "papermill": {
     "duration": 0.103619,
     "end_time": "2024-05-28T15:50:45.859912",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.756293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range:\n",
      " DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
      "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
      "               '2023-01-09', '2023-01-10'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "\n",
      "Time Series:\n",
      " 2023-01-01    0.581692\n",
      "2023-01-02    1.350540\n",
      "2023-01-03   -0.706632\n",
      "2023-01-04    0.189312\n",
      "2023-01-05    1.085120\n",
      "2023-01-06   -0.508063\n",
      "2023-01-07   -1.023770\n",
      "2023-01-08   -0.996731\n",
      "2023-01-09   -1.139132\n",
      "2023-01-10   -0.932358\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Localized Time Series (UTC):\n",
      " 2023-01-01 00:00:00+00:00    0.581692\n",
      "2023-01-02 00:00:00+00:00    1.350540\n",
      "2023-01-03 00:00:00+00:00   -0.706632\n",
      "2023-01-04 00:00:00+00:00    0.189312\n",
      "2023-01-05 00:00:00+00:00    1.085120\n",
      "2023-01-06 00:00:00+00:00   -0.508063\n",
      "2023-01-07 00:00:00+00:00   -1.023770\n",
      "2023-01-08 00:00:00+00:00   -0.996731\n",
      "2023-01-09 00:00:00+00:00   -1.139132\n",
      "2023-01-10 00:00:00+00:00   -0.932358\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Converted Time Series (US/Eastern):\n",
      " 2022-12-31 19:00:00-05:00    0.581692\n",
      "2023-01-01 19:00:00-05:00    1.350540\n",
      "2023-01-02 19:00:00-05:00   -0.706632\n",
      "2023-01-03 19:00:00-05:00    0.189312\n",
      "2023-01-04 19:00:00-05:00    1.085120\n",
      "2023-01-05 19:00:00-05:00   -0.508063\n",
      "2023-01-06 19:00:00-05:00   -1.023770\n",
      "2023-01-07 19:00:00-05:00   -0.996731\n",
      "2023-01-08 19:00:00-05:00   -1.139132\n",
      "2023-01-09 19:00:00-05:00   -0.932358\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Weekly Resampled Series:\n",
      " 2023-01-01    0.581692\n",
      "2023-01-08   -0.087175\n",
      "2023-01-15   -1.035745\n",
      "Freq: W-SUN, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date Range Generation\n",
    "date_range = pd.date_range(start='2023-01-01', periods=10, freq='D')\n",
    "print(\"Date Range:\\n\", date_range)\n",
    "\n",
    "# Creating a time series with random data\n",
    "time_series = pd.Series(np.random.randn(10), index=date_range)\n",
    "print(\"\\nTime Series:\\n\", time_series)\n",
    "\n",
    "# Time Zone Handling\n",
    "# Localize the time series to a specific time zone\n",
    "localized_series = time_series.tz_localize('UTC')\n",
    "print(\"\\nLocalized Time Series (UTC):\\n\", localized_series)\n",
    "\n",
    "# Convert the time series to a different time zone\n",
    "converted_series = localized_series.tz_convert('US/Eastern')\n",
    "print(\"\\nConverted Time Series (US/Eastern):\\n\", converted_series)\n",
    "\n",
    "# Time Series Resampling\n",
    "# Resampling to a different frequency (e.g., weekly)\n",
    "weekly_series = time_series.resample('W').mean()\n",
    "print(\"\\nWeekly Resampled Series:\\n\", weekly_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea5b8f",
   "metadata": {
    "papermill": {
     "duration": 0.010559,
     "end_time": "2024-05-28T15:50:45.881483",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.870924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Merging, Joining, and Concatenating\n",
    "\n",
    "Combining multiple DataFrames is a common task in data analysis. pandas provides several methods to accomplish this, including concatenation, merging, and joining.\n",
    "\n",
    "### Concatenating DataFrames\n",
    "Concatenation combines multiple DataFrames along a particular axis.\n",
    "\n",
    "### Merging on Index\n",
    "Merging allows you to combine DataFrames based on their index or a common column.\n",
    "\n",
    "### Advanced Joining Techniques\n",
    "Advanced joining techniques involve performing SQL-like joins with DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09f19c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:45.905345Z",
     "iopub.status.busy": "2024-05-28T15:50:45.904963Z",
     "iopub.status.idle": "2024-05-28T15:50:45.936978Z",
     "shell.execute_reply": "2024-05-28T15:50:45.935032Z"
    },
    "papermill": {
     "duration": 0.047454,
     "end_time": "2024-05-28T15:50:45.939720",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.892266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "       Name    Race\n",
      "0    Frodo  Hobbit\n",
      "1      Sam  Hobbit\n",
      "2  Gandalf  Wizard\n",
      "0  Aragorn   Human\n",
      "1  Legolas     Elf\n",
      "2    Gimli   Dwarf\n",
      "\n",
      "Merged DataFrame (inner join):\n",
      "       Name    Race Weapon\n",
      "0    Frodo  Hobbit  Sting\n",
      "1      Sam  Hobbit  Sword\n",
      "2  Gandalf  Wizard  Staff\n",
      "\n",
      "Left Join DataFrame:\n",
      "       Name    Race Weapon\n",
      "0    Frodo  Hobbit  Sting\n",
      "1      Sam  Hobbit  Sword\n",
      "2  Gandalf  Wizard  Staff\n",
      "\n",
      "Right Join DataFrame:\n",
      "         Name Race   Weapon\n",
      "NaN  Aragorn  NaN  Anduril\n",
      "NaN  Legolas  NaN      Bow\n",
      "NaN    Gimli  NaN      Axe\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'Name': ['Frodo', 'Sam', 'Gandalf'],\n",
    "    'Race': ['Hobbit', 'Hobbit', 'Wizard']\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['Aragorn', 'Legolas', 'Gimli'],\n",
    "    'Race': ['Human', 'Elf', 'Dwarf']\n",
    "})\n",
    "\n",
    "# Concatenating DataFrames\n",
    "concat_df = pd.concat([df1, df2])\n",
    "print(\"Concatenated DataFrame:\\n\", concat_df)\n",
    "\n",
    "# Creating DataFrames for merging\n",
    "df3 = pd.DataFrame({\n",
    "    'Name': ['Frodo', 'Sam', 'Gandalf'],\n",
    "    'Weapon': ['Sting', 'Sword', 'Staff']\n",
    "})\n",
    "df4 = pd.DataFrame({\n",
    "    'Name': ['Aragorn', 'Legolas', 'Gimli'],\n",
    "    'Weapon': ['Anduril', 'Bow', 'Axe']\n",
    "})\n",
    "\n",
    "# Merging DataFrames on a common column\n",
    "merged_df = pd.merge(df1, df3, on='Name', how='inner')\n",
    "print(\"\\nMerged DataFrame (inner join):\\n\", merged_df)\n",
    "\n",
    "# Advanced Joining Techniques\n",
    "# Left join\n",
    "left_join_df = df1.join(df3.set_index('Name'), on='Name', how='left')\n",
    "print(\"\\nLeft Join DataFrame:\\n\", left_join_df)\n",
    "\n",
    "# Right join\n",
    "right_join_df = df1.join(df4.set_index('Name'), on='Name', how='right')\n",
    "print(\"\\nRight Join DataFrame:\\n\", right_join_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61708e0e",
   "metadata": {
    "papermill": {
     "duration": 0.011328,
     "end_time": "2024-05-28T15:50:45.962120",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.950792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Window Functions\n",
    "\n",
    "Window functions in pandas allow you to perform operations over a specified window or rolling time frame. These functions are useful for smoothing, trend analysis, and other time series operations.\n",
    "\n",
    "### Rolling Windows\n",
    "Applying operations over a rolling window of specified size.\n",
    "\n",
    "### Expanding Windows\n",
    "Applying cumulative operations over an expanding window.\n",
    "\n",
    "### Applying Custom Functions\n",
    "Using custom functions with rolling and expanding windows for more complex calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5de3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:45.987482Z",
     "iopub.status.busy": "2024-05-28T15:50:45.986299Z",
     "iopub.status.idle": "2024-05-28T15:50:46.005084Z",
     "shell.execute_reply": "2024-05-28T15:50:46.003057Z"
    },
    "papermill": {
     "duration": 0.034936,
     "end_time": "2024-05-28T15:50:46.008325",
     "exception": false,
     "start_time": "2024-05-28T15:50:45.973389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Time Series:\n",
      " 2023-01-01    0.157666\n",
      "2023-01-02    0.089719\n",
      "2023-01-03    0.617544\n",
      "2023-01-04   -0.164820\n",
      "2023-01-05    0.086518\n",
      "2023-01-06   -0.190851\n",
      "2023-01-07   -0.786600\n",
      "2023-01-08   -0.083808\n",
      "2023-01-09   -0.704289\n",
      "2023-01-10   -0.468537\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Rolling Mean (3-day window):\n",
      " 2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    0.288310\n",
      "2023-01-04    0.180814\n",
      "2023-01-05    0.179748\n",
      "2023-01-06   -0.089718\n",
      "2023-01-07   -0.296978\n",
      "2023-01-08   -0.353753\n",
      "2023-01-09   -0.524899\n",
      "2023-01-10   -0.418878\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Expanding Sum:\n",
      " 2023-01-01    0.157666\n",
      "2023-01-02    0.247385\n",
      "2023-01-03    0.864929\n",
      "2023-01-04    0.700109\n",
      "2023-01-05    0.786628\n",
      "2023-01-06    0.595776\n",
      "2023-01-07   -0.190824\n",
      "2023-01-08   -0.274632\n",
      "2023-01-09   -0.978921\n",
      "2023-01-10   -1.447457\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Rolling Range (3-day window):\n",
      " 2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    0.527825\n",
      "2023-01-04    0.782363\n",
      "2023-01-05    0.782363\n",
      "2023-01-06    0.277370\n",
      "2023-01-07    0.873119\n",
      "2023-01-08    0.702792\n",
      "2023-01-09    0.702792\n",
      "2023-01-10    0.620481\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a time series with random data\n",
    "date_range = pd.date_range(start='2023-01-01', periods=10, freq='D')\n",
    "time_series = pd.Series(np.random.randn(10), index=date_range)\n",
    "print(\"Original Time Series:\\n\", time_series)\n",
    "\n",
    "# Rolling Windows\n",
    "# Applying a rolling window of 3 days and calculating the mean\n",
    "rolling_mean = time_series.rolling(window=3).mean()\n",
    "print(\"\\nRolling Mean (3-day window):\\n\", rolling_mean)\n",
    "\n",
    "# Expanding Windows\n",
    "# Applying an expanding window and calculating the cumulative sum\n",
    "expanding_sum = time_series.expanding().sum()\n",
    "print(\"\\nExpanding Sum:\\n\", expanding_sum)\n",
    "\n",
    "# Applying Custom Functions\n",
    "# Custom function to calculate the range (max - min) over a rolling window\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "rolling_range = time_series.rolling(window=3).apply(range_func)\n",
    "print(\"\\nRolling Range (3-day window):\\n\", rolling_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d904dc",
   "metadata": {
    "papermill": {
     "duration": 0.010498,
     "end_time": "2024-05-28T15:50:46.030241",
     "exception": false,
     "start_time": "2024-05-28T15:50:46.019743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Text Data\n",
    "\n",
    "Working with text data in pandas involves various string operations, including manipulation, regular expressions, and extracting information from text. These operations are essential for cleaning and transforming text data.\n",
    "\n",
    "### String Methods\n",
    "pandas provides numerous built-in string methods for common text operations.\n",
    "\n",
    "### Regular Expressions\n",
    "Regular expressions (regex) are powerful tools for pattern matching and text extraction.\n",
    "\n",
    "### Extracting Information from Text\n",
    "You can extract specific information from text data using pandas' string methods and regex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b115822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:46.055189Z",
     "iopub.status.busy": "2024-05-28T15:50:46.054772Z",
     "iopub.status.idle": "2024-05-28T15:50:46.071233Z",
     "shell.execute_reply": "2024-05-28T15:50:46.069230Z"
    },
    "papermill": {
     "duration": 0.031747,
     "end_time": "2024-05-28T15:50:46.074088",
     "exception": false,
     "start_time": "2024-05-28T15:50:46.042341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " 0              Frodo Baggins\n",
      "1             Samwise Gamgee\n",
      "2           Gandalf the Grey\n",
      "3    Aragorn son of Arathorn\n",
      "4        Legolas of Mirkwood\n",
      "dtype: object\n",
      "\n",
      "Lowercase Series:\n",
      " 0              frodo baggins\n",
      "1             samwise gamgee\n",
      "2           gandalf the grey\n",
      "3    aragorn son of arathorn\n",
      "4        legolas of mirkwood\n",
      "dtype: object\n",
      "\n",
      "Length of each character name:\n",
      " 0    13\n",
      "1    14\n",
      "2    16\n",
      "3    23\n",
      "4    19\n",
      "dtype: int64\n",
      "\n",
      "Extracted First Names:\n",
      " 0      Frodo\n",
      "1    Samwise\n",
      "2    Gandalf\n",
      "3    Aragorn\n",
      "4    Legolas\n",
      "dtype: object\n",
      "\n",
      "Extracted Titles:\n",
      " 0                NaN\n",
      "1                NaN\n",
      "2           the Grey\n",
      "3    son of Arathorn\n",
      "4        of Mirkwood\n",
      "dtype: object\n",
      "\n",
      "Character names containing 'of':\n",
      " 0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a Series with text data\n",
    "characters = pd.Series(['Frodo Baggins', 'Samwise Gamgee', 'Gandalf the Grey', 'Aragorn son of Arathorn', 'Legolas of Mirkwood'])\n",
    "print(\"Original Series:\\n\", characters)\n",
    "\n",
    "# String Methods\n",
    "# Converting to lowercase\n",
    "lowercase_characters = characters.str.lower()\n",
    "print(\"\\nLowercase Series:\\n\", lowercase_characters)\n",
    "\n",
    "# Extracting length of each string\n",
    "length_characters = characters.str.len()\n",
    "print(\"\\nLength of each character name:\\n\", length_characters)\n",
    "\n",
    "# Regular Expressions\n",
    "# Extracting first names using regex\n",
    "first_names = characters.str.extract(r'(\\w+)', expand=False)\n",
    "print(\"\\nExtracted First Names:\\n\", first_names)\n",
    "\n",
    "# Extracting titles (e.g., \"the Grey\", \"son of Arathorn\")\n",
    "titles = characters.str.extract(r'(the \\w+|son of \\w+|of \\w+)', expand=False)\n",
    "print(\"\\nExtracted Titles:\\n\", titles)\n",
    "\n",
    "# Extracting Information from Text\n",
    "# Checking if the character name contains \"of\"\n",
    "contains_of = characters.str.contains('of')\n",
    "print(\"\\nCharacter names containing 'of':\\n\", contains_of)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac507322",
   "metadata": {
    "papermill": {
     "duration": 0.010699,
     "end_time": "2024-05-28T15:50:46.096886",
     "exception": false,
     "start_time": "2024-05-28T15:50:46.086187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Performance and Optimization\n",
    "\n",
    "Optimizing the performance of your pandas code is crucial for handling large datasets efficiently. This section covers techniques for efficient data loading, reducing memory usage, and parallel processing.\n",
    "\n",
    "### Efficient Data Loading\n",
    "Loading data efficiently using various methods provided by pandas.\n",
    "\n",
    "### Memory Usage Reduction\n",
    "Techniques to reduce memory usage by optimizing data types and other strategies.\n",
    "\n",
    "### Parallel Processing\n",
    "Leveraging parallel processing to speed up computations on large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecc438a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:46.121367Z",
     "iopub.status.busy": "2024-05-28T15:50:46.120834Z",
     "iopub.status.idle": "2024-05-28T15:50:47.726046Z",
     "shell.execute_reply": "2024-05-28T15:50:47.725042Z"
    },
    "papermill": {
     "duration": 1.620859,
     "end_time": "2024-05-28T15:50:47.728707",
     "exception": false,
     "start_time": "2024-05-28T15:50:46.107848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame memory usage:\n",
      " Index        128\n",
      "A        8000000\n",
      "B        8000000\n",
      "dtype: int64\n",
      "\n",
      "Optimized DataFrame memory usage:\n",
      " Index        128\n",
      "A        2000000\n",
      "B        2000000\n",
      "dtype: int64\n",
      "\n",
      "Original mixed DataFrame memory usage:\n",
      " Index        128\n",
      "integers    8000\n",
      "floats      8000\n",
      "strings     8000\n",
      "dtype: int64\n",
      "\n",
      "Optimized mixed DataFrame memory usage:\n",
      " Index         128\n",
      "integers     8000\n",
      "floats       8000\n",
      "strings     43064\n",
      "dtype: int64\n",
      "\n",
      "Parallel computation with Dask:\n",
      "             B\n",
      "A            \n",
      "0   49.594467\n",
      "1   49.462999\n",
      "2   49.676426\n",
      "3   49.573739\n",
      "4   49.680146\n",
      "..        ...\n",
      "95  49.211500\n",
      "96  49.664722\n",
      "97  49.512751\n",
      "98  50.021618\n",
      "99  49.798630\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Efficient Data Loading\n",
    "# Using a smaller data type for integers\n",
    "data = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 100, size=1000000),\n",
    "    'B': np.random.randint(0, 100, size=1000000)\n",
    "})\n",
    "print(\"Original DataFrame memory usage:\\n\", data.memory_usage(deep=True))\n",
    "\n",
    "# Convert integer columns to smaller data types\n",
    "data['A'] = data['A'].astype(np.int16)\n",
    "data['B'] = data['B'].astype(np.int16)\n",
    "print(\"\\nOptimized DataFrame memory usage:\\n\", data.memory_usage(deep=True))\n",
    "\n",
    "# Memory Usage Reduction\n",
    "# Creating a DataFrame with mixed data types\n",
    "data_mixed = pd.DataFrame({\n",
    "    'integers': np.random.randint(0, 100, size=1000),\n",
    "    'floats': np.random.rand(1000),\n",
    "    'strings': pd.Series(pd.util.hash_pandas_object(pd.Series(np.random.rand(1000).astype(str))))\n",
    "})\n",
    "print(\"\\nOriginal mixed DataFrame memory usage:\\n\", data_mixed.memory_usage(deep=True))\n",
    "\n",
    "# Convert strings to category type\n",
    "data_mixed['strings'] = data_mixed['strings'].astype('category')\n",
    "print(\"\\nOptimized mixed DataFrame memory usage:\\n\", data_mixed.memory_usage(deep=True))\n",
    "\n",
    "# Parallel Processing\n",
    "# Using Dask to handle large datasets with parallel processing\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Convert pandas DataFrame to Dask DataFrame\n",
    "dask_df = dd.from_pandas(data, npartitions=4)\n",
    "\n",
    "# Perform parallel computation with Dask\n",
    "result = dask_df.groupby('A').mean().compute()\n",
    "print(\"\\nParallel computation with Dask:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbd21d8",
   "metadata": {
    "papermill": {
     "duration": 0.011187,
     "end_time": "2024-05-28T15:50:47.751649",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.740462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Challenge 1: The MultiIndex Mystery\n",
    "\n",
    "You are given a DataFrame with a MultiIndex. Your task is to perform the following operations:\n",
    "\n",
    "1. Access the data for a specific level of the MultiIndex.\n",
    "2. Slice the data for a range of values in one of the levels.\n",
    "3. Perform an aggregation on one of the levels.\n",
    "\n",
    "**Dataset:**\n",
    "- Characters and their attributes from \"The Lord of the Rings\"\n",
    "\n",
    "Perform these operations and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859a37fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:47.776726Z",
     "iopub.status.busy": "2024-05-28T15:50:47.776046Z",
     "iopub.status.idle": "2024-05-28T15:50:47.786327Z",
     "shell.execute_reply": "2024-05-28T15:50:47.785026Z"
    },
    "papermill": {
     "duration": 0.025643,
     "end_time": "2024-05-28T15:50:47.788702",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.763059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "arrays = [\n",
    "    ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf'],\n",
    "    ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas']\n",
    "]\n",
    "multi_index = pd.MultiIndex.from_arrays(arrays, names=('Race', 'Character'))\n",
    "data = {\n",
    "    'Age': [50, 38, 2019, 87, 2931],\n",
    "    'Role': ['Ring-bearer', 'Gardener', 'Wizard', 'King', 'Archer']\n",
    "}\n",
    "df_multi = pd.DataFrame(data, index=multi_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2607ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:47.813507Z",
     "iopub.status.busy": "2024-05-28T15:50:47.812909Z",
     "iopub.status.idle": "2024-05-28T15:50:47.829991Z",
     "shell.execute_reply": "2024-05-28T15:50:47.828058Z"
    },
    "papermill": {
     "duration": 0.033345,
     "end_time": "2024-05-28T15:50:47.833151",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.799806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data for 'Hobbit' race:\n",
      "            Age         Role\n",
      "Character                  \n",
      "Frodo       50  Ring-bearer\n",
      "Sam         38     Gardener\n",
      "\n",
      "Data for 'Hobbit' and 'Wizard' races:\n",
      "                    Age         Role\n",
      "Race   Character                   \n",
      "Hobbit Frodo        50  Ring-bearer\n",
      "       Sam          38     Gardener\n",
      "Wizard Gandalf    2019       Wizard\n",
      "\n",
      "Mean age by race:\n",
      " Race\n",
      "Elf       2931.0\n",
      "Hobbit      44.0\n",
      "Human       87.0\n",
      "Wizard    2019.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Access the data for 'Hobbit' race\n",
    "hobbit_data = df_multi.loc['Hobbit']\n",
    "print(\"\\nData for 'Hobbit' race:\\n\", hobbit_data)\n",
    "\n",
    "# Step 2: Slice the data for 'Hobbit' and 'Wizard' races\n",
    "hobbit_wizard_data = df_multi.loc[['Hobbit', 'Wizard']]\n",
    "print(\"\\nData for 'Hobbit' and 'Wizard' races:\\n\", hobbit_wizard_data)\n",
    "\n",
    "# Step 3: Perform an aggregation on the 'Race' level (mean age)\n",
    "mean_age_by_race = df_multi.groupby('Race')['Age'].mean()\n",
    "print(\"\\nMean age by race:\\n\", mean_age_by_race)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d33c3",
   "metadata": {
    "papermill": {
     "duration": 0.011297,
     "end_time": "2024-05-28T15:50:47.856510",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.845213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Challenge 2: The GroupBy Gauntlet\n",
    "\n",
    "You are given a DataFrame of characters and their attributes from \"The Lord of the Rings.\" Your task is to perform the following operations:\n",
    "\n",
    "1. Group the data by 'Race' and calculate the mean 'Age'.\n",
    "2. Apply a custom aggregation to calculate the range of 'Age' within each 'Race'.\n",
    "3. Group the data using a custom function to classify characters as 'Young' or 'Old' based on their age.\n",
    "\n",
    "Perform these operations and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1799af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:47.882222Z",
     "iopub.status.busy": "2024-05-28T15:50:47.881722Z",
     "iopub.status.idle": "2024-05-28T15:50:47.889468Z",
     "shell.execute_reply": "2024-05-28T15:50:47.888324Z"
    },
    "papermill": {
     "duration": 0.023502,
     "end_time": "2024-05-28T15:50:47.891723",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.868221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Character': ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas', 'Boromir', 'Gimli', 'Pippin', 'Merry'],\n",
    "    'Race': ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf', 'Human', 'Dwarf', 'Hobbit', 'Hobbit'],\n",
    "    'Age': [50, 38, 2019, 87, 2931, 41, 139, 29, 37]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df52c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:47.917279Z",
     "iopub.status.busy": "2024-05-28T15:50:47.916611Z",
     "iopub.status.idle": "2024-05-28T15:50:47.940263Z",
     "shell.execute_reply": "2024-05-28T15:50:47.938793Z"
    },
    "papermill": {
     "duration": 0.039554,
     "end_time": "2024-05-28T15:50:47.943245",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.903691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age by race:\n",
      " Race\n",
      "Dwarf      139.0\n",
      "Elf       2931.0\n",
      "Hobbit      38.5\n",
      "Human       64.0\n",
      "Wizard    2019.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Age range by race:\n",
      "         age_range\n",
      "Race             \n",
      "Dwarf           0\n",
      "Elf             0\n",
      "Hobbit         21\n",
      "Human          46\n",
      "Wizard          0\n",
      "\n",
      "Grouped by Age Group:\n",
      " AgeGroup\n",
      "Old      1696.333333\n",
      "Young      47.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'Race' and calculate the mean 'Age'\n",
    "mean_age_by_race = df.groupby('Race')['Age'].mean()\n",
    "print(\"Mean age by race:\\n\", mean_age_by_race)\n",
    "\n",
    "# Step 2: Custom aggregation to calculate the range of 'Age' within each 'Race'\n",
    "def range_agg(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Ensure that only numeric data is used for the custom aggregation\n",
    "age_range_by_race = df.groupby('Race').agg(\n",
    "    age_range=pd.NamedAgg(column='Age', aggfunc=range_agg)\n",
    ")\n",
    "print(\"\\nAge range by race:\\n\", age_range_by_race)\n",
    "\n",
    "# Step 3: Group data using a custom function to classify characters as 'Young' or 'Old'\n",
    "def age_group(age):\n",
    "    return 'Young' if age < 100 else 'Old'\n",
    "\n",
    "df['AgeGroup'] = df['Age'].apply(age_group)\n",
    "grouped_by_age_group = df.groupby('AgeGroup')['Age'].mean()\n",
    "print(\"\\nGrouped by Age Group:\\n\", grouped_by_age_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0db2c9",
   "metadata": {
    "papermill": {
     "duration": 0.011279,
     "end_time": "2024-05-28T15:50:47.966584",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.955305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Challenge 3: The Reshaping Riddle\n",
    "\n",
    "You are given a DataFrame of characters and their attributes from \"The Lord of the Rings.\" Your task is to perform the following operations:\n",
    "\n",
    "1. Pivot the data to create a summary table of ages by race and role.\n",
    "2. Stack the data to convert columns into rows.\n",
    "3. Unstack the data to convert rows into columns.\n",
    "4. Melt the data to convert it from wide to long format.\n",
    "\n",
    "Perform these operations and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e91aff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:47.992056Z",
     "iopub.status.busy": "2024-05-28T15:50:47.991571Z",
     "iopub.status.idle": "2024-05-28T15:50:47.999416Z",
     "shell.execute_reply": "2024-05-28T15:50:47.997963Z"
    },
    "papermill": {
     "duration": 0.023822,
     "end_time": "2024-05-28T15:50:48.002024",
     "exception": false,
     "start_time": "2024-05-28T15:50:47.978202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Character': ['Frodo', 'Sam', 'Gandalf', 'Aragorn', 'Legolas'],\n",
    "    'Race': ['Hobbit', 'Hobbit', 'Wizard', 'Human', 'Elf'],\n",
    "    'Age': [50, 38, 2019, 87, 2931],\n",
    "    'Role': ['Ring-bearer', 'Gardener', 'Wizard', 'King', 'Archer']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7433d47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:48.028131Z",
     "iopub.status.busy": "2024-05-28T15:50:48.027717Z",
     "iopub.status.idle": "2024-05-28T15:50:48.065717Z",
     "shell.execute_reply": "2024-05-28T15:50:48.063549Z"
    },
    "papermill": {
     "duration": 0.054835,
     "end_time": "2024-05-28T15:50:48.069324",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.014489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table:\n",
      " Role    Archer  Gardener  King  Ring-bearer  Wizard\n",
      "Race                                               \n",
      "Elf     2931.0       NaN   NaN          NaN     NaN\n",
      "Hobbit     NaN      38.0   NaN         50.0     NaN\n",
      "Human      NaN       NaN  87.0          NaN     NaN\n",
      "Wizard     NaN       NaN   NaN          NaN  2019.0\n",
      "\n",
      "Stacked DataFrame:\n",
      " Race    Character      \n",
      "Hobbit  Frodo      Age              50\n",
      "                   Role    Ring-bearer\n",
      "        Sam        Age              38\n",
      "                   Role       Gardener\n",
      "Wizard  Gandalf    Age            2019\n",
      "                   Role         Wizard\n",
      "Human   Aragorn    Age              87\n",
      "                   Role           King\n",
      "Elf     Legolas    Age            2931\n",
      "                   Role         Archer\n",
      "dtype: object\n",
      "\n",
      "Unstacked DataFrame:\n",
      "                    Age         Role\n",
      "Race   Character                   \n",
      "Elf    Legolas    2931       Archer\n",
      "Hobbit Frodo        50  Ring-bearer\n",
      "       Sam          38     Gardener\n",
      "Human  Aragorn      87         King\n",
      "Wizard Gandalf    2019       Wizard\n",
      "\n",
      "Melted DataFrame:\n",
      "    Character Attribute        Value\n",
      "0      Frodo      Race       Hobbit\n",
      "1        Sam      Race       Hobbit\n",
      "2    Gandalf      Race       Wizard\n",
      "3    Aragorn      Race        Human\n",
      "4    Legolas      Race          Elf\n",
      "5      Frodo       Age           50\n",
      "6        Sam       Age           38\n",
      "7    Gandalf       Age         2019\n",
      "8    Aragorn       Age           87\n",
      "9    Legolas       Age         2931\n",
      "10     Frodo      Role  Ring-bearer\n",
      "11       Sam      Role     Gardener\n",
      "12   Gandalf      Role       Wizard\n",
      "13   Aragorn      Role         King\n",
      "14   Legolas      Role       Archer\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Pivot the data to create a summary table of ages by race and role\n",
    "pivot_table = df.pivot_table(values='Age', index='Race', columns='Role', aggfunc='mean')\n",
    "print(\"Pivot Table:\\n\", pivot_table)\n",
    "\n",
    "# Step 2: Stack the data to convert columns into rows\n",
    "stacked = df.set_index(['Race', 'Character']).stack()\n",
    "print(\"\\nStacked DataFrame:\\n\", stacked)\n",
    "\n",
    "# Step 3: Unstack the data to convert rows into columns\n",
    "unstacked = stacked.unstack()\n",
    "print(\"\\nUnstacked DataFrame:\\n\", unstacked)\n",
    "\n",
    "# Step 4: Melt the data to convert it from wide to long format\n",
    "melted = pd.melt(df, id_vars=['Character'], value_vars=['Race', 'Age', 'Role'], var_name='Attribute', value_name='Value')\n",
    "print(\"\\nMelted DataFrame:\\n\", melted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624fd0ed",
   "metadata": {
    "papermill": {
     "duration": 0.011287,
     "end_time": "2024-05-28T15:50:48.092879",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.081592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Challenge 4: The Time Series Trial\n",
    "\n",
    "You are given a time series dataset with daily observations. Your task is to perform the following operations:\n",
    "\n",
    "1. Generate a date range and create a time series with random data.\n",
    "2. Resample the data to a weekly frequency and calculate the mean.\n",
    "3. Shift the data forward by 2 days.\n",
    "4. Calculate the rolling mean with a window of 3 days.\n",
    "\n",
    "Perform these operations and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9e049a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:48.118888Z",
     "iopub.status.busy": "2024-05-28T15:50:48.118407Z",
     "iopub.status.idle": "2024-05-28T15:50:48.135393Z",
     "shell.execute_reply": "2024-05-28T15:50:48.134094Z"
    },
    "papermill": {
     "duration": 0.03455,
     "end_time": "2024-05-28T15:50:48.138895",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.104345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Time Series:\n",
      " 2023-01-01    1.488081\n",
      "2023-01-02    0.027298\n",
      "2023-01-03   -0.729678\n",
      "2023-01-04    1.745853\n",
      "2023-01-05    0.442168\n",
      "2023-01-06   -1.280220\n",
      "2023-01-07   -0.922605\n",
      "2023-01-08    0.746070\n",
      "2023-01-09   -0.673303\n",
      "2023-01-10    1.189986\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Weekly Resampled Series (Mean):\n",
      " 2023-01-01    1.488081\n",
      "2023-01-08    0.004127\n",
      "2023-01-15    0.258341\n",
      "Freq: W-SUN, dtype: float64\n",
      "\n",
      "Shifted Series (Forward by 2 days):\n",
      " 2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    1.488081\n",
      "2023-01-04    0.027298\n",
      "2023-01-05   -0.729678\n",
      "2023-01-06    1.745853\n",
      "2023-01-07    0.442168\n",
      "2023-01-08   -1.280220\n",
      "2023-01-09   -0.922605\n",
      "2023-01-10    0.746070\n",
      "Freq: D, dtype: float64\n",
      "\n",
      "Rolling Mean Series (3-day window):\n",
      " 2023-01-01         NaN\n",
      "2023-01-02         NaN\n",
      "2023-01-03    0.261900\n",
      "2023-01-04    0.347824\n",
      "2023-01-05    0.486114\n",
      "2023-01-06    0.302600\n",
      "2023-01-07   -0.586886\n",
      "2023-01-08   -0.485585\n",
      "2023-01-09   -0.283279\n",
      "2023-01-10    0.420918\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate a date range and create a time series with random data\n",
    "date_range = pd.date_range(start='2023-01-01', periods=10, freq='D')\n",
    "time_series = pd.Series(np.random.randn(10), index=date_range)\n",
    "print(\"Original Time Series:\\n\", time_series)\n",
    "\n",
    "# Step 2: Resample the data to a weekly frequency and calculate the mean\n",
    "weekly_series = time_series.resample('W').mean()\n",
    "print(\"\\nWeekly Resampled Series (Mean):\\n\", weekly_series)\n",
    "\n",
    "# Step 3: Shift the data forward by 2 days\n",
    "shifted_series = time_series.shift(2)\n",
    "print(\"\\nShifted Series (Forward by 2 days):\\n\", shifted_series)\n",
    "\n",
    "# Step 4: Calculate the rolling mean with a window of 3 days\n",
    "rolling_mean_series = time_series.rolling(window=3).mean()\n",
    "print(\"\\nRolling Mean Series (3-day window):\\n\", rolling_mean_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0bfb0",
   "metadata": {
    "papermill": {
     "duration": 0.012181,
     "end_time": "2024-05-28T15:50:48.163838",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.151657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Challenge 5: The Optimization Obstacle\n",
    "\n",
    "You are given a DataFrame with mixed data types. Your task is to perform the following operations:\n",
    "\n",
    "1. Optimize the DataFrame by converting data types to more efficient ones.\n",
    "2. Measure the memory usage before and after optimization.\n",
    "3. Perform a parallel computation using Dask to handle large datasets.\n",
    "\n",
    "Perform these operations and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ab2b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:48.191271Z",
     "iopub.status.busy": "2024-05-28T15:50:48.190793Z",
     "iopub.status.idle": "2024-05-28T15:50:48.281034Z",
     "shell.execute_reply": "2024-05-28T15:50:48.278806Z"
    },
    "papermill": {
     "duration": 0.10799,
     "end_time": "2024-05-28T15:50:48.284245",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.176255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame memory usage:\n",
      " Index           128\n",
      "integers     800000\n",
      "floats       800000\n",
      "strings     6788890\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Given DataFrame with mixed data types\n",
    "data = pd.DataFrame({\n",
    "    'integers': np.random.randint(0, 100, size=100000),\n",
    "    'floats': np.random.rand(100000),\n",
    "    'strings': pd.Series(['string' + str(i) for i in range(100000)])\n",
    "})\n",
    "print(\"Original DataFrame memory usage:\\n\", data.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65005c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:50:48.311108Z",
     "iopub.status.busy": "2024-05-28T15:50:48.310608Z",
     "iopub.status.idle": "2024-05-28T15:50:48.865650Z",
     "shell.execute_reply": "2024-05-28T15:50:48.863938Z"
    },
    "papermill": {
     "duration": 0.571818,
     "end_time": "2024-05-28T15:50:48.868445",
     "exception": false,
     "start_time": "2024-05-28T15:50:48.296627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized DataFrame memory usage:\n",
      " Index           128\n",
      "integers     200000\n",
      "floats       400000\n",
      "strings     9302466\n",
      "dtype: int64\n",
      "\n",
      "Memory usage before optimization: 9902594 bytes\n",
      "Memory usage after optimization: 9902594 bytes\n",
      "\n",
      "Parallel computation result using Dask:\n",
      " integers\n",
      "0     0.503266\n",
      "1     0.496368\n",
      "2     0.489691\n",
      "3     0.504265\n",
      "4     0.505815\n",
      "        ...   \n",
      "95    0.499826\n",
      "96    0.490031\n",
      "97    0.499781\n",
      "98    0.497330\n",
      "99    0.494543\n",
      "Name: floats, Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Optimize the DataFrame by converting data types\n",
    "data['integers'] = data['integers'].astype(np.int16)\n",
    "data['floats'] = data['floats'].astype(np.float32)\n",
    "data['strings'] = data['strings'].astype('category')\n",
    "print(\"\\nOptimized DataFrame memory usage:\\n\", data.memory_usage(deep=True))\n",
    "\n",
    "# Step 2: Measure memory usage before and after optimization\n",
    "memory_before = data.memory_usage(deep=True).sum()\n",
    "data['integers'] = data['integers'].astype(np.int16)\n",
    "data['floats'] = data['floats'].astype(np.float32)\n",
    "data['strings'] = data['strings'].astype('category')\n",
    "memory_after = data.memory_usage(deep=True).sum()\n",
    "print(\"\\nMemory usage before optimization: {} bytes\".format(memory_before))\n",
    "print(\"Memory usage after optimization: {} bytes\".format(memory_after))\n",
    "\n",
    "# Step 3: Perform a parallel computation using Dask\n",
    "# Convert pandas DataFrame to Dask DataFrame\n",
    "dask_df = dd.from_pandas(data[['integers', 'floats']], npartitions=4)\n",
    "\n",
    "# Perform a parallel computation (mean of each group of 'integers')\n",
    "result = dask_df.groupby('integers').floats.mean().compute()\n",
    "print(\"\\nParallel computation result using Dask:\\n\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.289341,
   "end_time": "2024-05-28T15:50:49.603813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-28T15:50:41.314472",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
