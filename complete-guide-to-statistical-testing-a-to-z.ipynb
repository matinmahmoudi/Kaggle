{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acddfc87",
   "metadata": {
    "papermill": {
     "duration": 0.005354,
     "end_time": "2024-05-16T13:45:40.195054",
     "exception": false,
     "start_time": "2024-05-16T13:45:40.189700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ”ï¸ ðŸ§© Complete Guide to Statistical Testing A to Z\n",
    "\n",
    "Welcome to this comprehensive guide on statistical testing! This notebook is designed to equip you with everything you need to know, from basic concepts to advanced applications in data science. Whether you're just starting out or you're a seasoned professional looking to sharpen your skills, this guide is for you!\n",
    "\n",
    "## What Will You Learn?\n",
    "\n",
    "We'll dive into a variety of statistical tests, each with a unique purpose in data analysis. By the end, you'll have a toolkit ready to tackle any data-driven challenge. Here's a peek at what we'll cover:\n",
    "\n",
    "- **Chi-Square Test:** Learn how to test relationships between categorical variables.\n",
    "- **Two-Sample T-Test & Paired T-Test:** Discover how to compare means from different groups and understand the statistical significance of their differences.\n",
    "- **ANOVA (Analysis of Variance):** Explore how to test differences across multiple groups simultaneously.\n",
    "- **Test of Correlation:** Uncover relationships and associations between continuous variables.\n",
    "- **A/B Testing (Continuous & Boolean Outcomes):** Master the art of comparing two versions of a variable to find the better-performing one in both continuous and binary outcomes.\n",
    "\n",
    "## Why This Guide?\n",
    "\n",
    "- **Step-by-Step Tutorials:** Each section includes clear explanations followed by practical examples, ensuring you not only learn but also apply your knowledge.\n",
    "- **Interactive Learning:** Engage with interactive code cells that allow you to see the effects of statistical tests in real-time.\n",
    "\n",
    "### How to Use This Notebook\n",
    "\n",
    "- **Run the Cells:** Follow along with the code examples by running the cells yourself. Play around with the parameters to see how the results change.\n",
    "- **Explore Further:** After completing the guided sections, try applying the tests to your own datasets to reinforce your learning.\n",
    "\n",
    "Get ready to unlock the full potential of statistical testing in data science. Let's dive in and turn data into decisions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d471b96",
   "metadata": {
    "papermill": {
     "duration": 0.004479,
     "end_time": "2024-05-16T13:45:40.204621",
     "exception": false,
     "start_time": "2024-05-16T13:45:40.200142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Description\n",
    "\n",
    "The dataset used in this notebook is `Sales_and_Satisfaction_V1.3.csv`. It contains information on sales and customer satisfaction before and after an intervention, along with purchase behavior. Below is a detailed description of each column, including the data types and a brief explanation.\n",
    "\n",
    "### Columns:\n",
    "\n",
    "1. **Group** (object)\n",
    "   - Indicates whether the entry is part of the control or treatment group.\n",
    "   - Example values: `Control`, `Treatment`\n",
    "   \n",
    "\n",
    "2. **Customer_Segment** (object)\n",
    "   - Segments customers into different value groups.\n",
    "   - Example values: `High Value`, `Medium Value`\n",
    "   \n",
    "\n",
    "3. **Sales_Before** (float64)\n",
    "   - Sales amount before the intervention.\n",
    "   - Example values: `216.21`, `225.09`\n",
    "   \n",
    "\n",
    "4. **Sales_After** (float64)\n",
    "   - Sales amount after the intervention.\n",
    "   - Example values: `246.87`, `257.57`\n",
    "   \n",
    "\n",
    "5. **Customer_Satisfaction_Before** (float64)\n",
    "   - Customer satisfaction score before the intervention.\n",
    "   - Example values: `58.93`, `84.71`\n",
    "   \n",
    "\n",
    "6. **Customer_Satisfaction_After** (float64)\n",
    "   - Customer satisfaction score after the intervention.\n",
    "   - Example values: `61.60`, `83.84`\n",
    "   \n",
    "\n",
    "7. **Purchase_Made** (object)\n",
    "   - Indicates whether a purchase was made.\n",
    "   - Example values: `Yes`, `No`\n",
    "   \n",
    "\n",
    "### Dataset Overview:\n",
    "\n",
    "- **Total Entries:** 10,000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8272d",
   "metadata": {
    "papermill": {
     "duration": 0.004451,
     "end_time": "2024-05-16T13:45:40.213756",
     "exception": false,
     "start_time": "2024-05-16T13:45:40.209305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chi-Square Test\n",
    "\n",
    "The Chi-Square Test determines whether there is a significant association between two categorical variables.\n",
    "\n",
    "## What is the Chi-Square Test?\n",
    "\n",
    "A non-parametric test that assesses whether observed frequency distributions align with expected distributions under the null hypothesis.\n",
    "\n",
    "## When to Use the Chi-Square Test\n",
    "\n",
    "- Variables are categorical.\n",
    "- Sample data is randomly drawn.\n",
    "- Expected frequency for each cell is at least 5.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. Data should be randomly sampled.\n",
    "2. Each expected frequency should be at least 5. If not, use Fisher's Exact Test for small sample sizes.\n",
    "\n",
    "## Hypotheses for Chi-Square Test for Independence\n",
    "\n",
    "- **Null Hypothesis (H0)**: No association between the categorical variables (independent).\n",
    "- **Alternative Hypothesis (H1)**: An association exists between the categorical variables (not independent).\n",
    "\n",
    "## Step-by-Step Guide\n",
    "\n",
    "1. **Create a Contingency Table**: Displays the frequency distribution of variables.\n",
    "2. **Calculate the Chi-Square Statistic**:\n",
    "\n",
    "   $$\n",
    "   \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "   $$\n",
    "   \n",
    "   where \\( O_i \\) is the observed frequency and \\( E_i \\) is the expected frequency.\n",
    "3. **Determine the p-value**: Compare the Chi-Square statistic to a Chi-Square distribution with degrees of freedom:\n",
    "\n",
    "   $$\n",
    "   df = (r-1) \\times (c-1)\n",
    "   $$\n",
    "   \n",
    "4. **Interpret the Results**: If the p-value is â‰¤ 0.05, reject the null hypothesis.\n",
    "\n",
    "## Odds Ratio\n",
    "\n",
    "The odds ratio measures the association between two categorical variables. It represents the odds that an outcome will occur given a particular exposure compared to the odds of the outcome occurring without that exposure.\n",
    "\n",
    "### When to Use the Odds Ratio\n",
    "\n",
    "The odds ratio is particularly useful when you have found a significant association between two categorical variables using the Chi-Square Test or Fisher's Exact Test. It helps to quantify the strength and direction of the association.\n",
    "\n",
    "### Calculating the Odds Ratio\n",
    "\n",
    "For a 2x2 contingency table:\n",
    "\n",
    "|                | Outcome Present (Yes) | Outcome Absent (No) |\n",
    "|----------------|------------------------|---------------------|\n",
    "| Exposure (Yes) | \\( a \\)                | \\( b \\)             |\n",
    "| No Exposure    | \\( c \\)                | \\( d \\)             |\n",
    "\n",
    "The odds ratio (OR) is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Odds Ratio} = \\frac{(a \\cdot d)}{(b \\cdot c)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( a \\) = Number of cases with exposure and outcome present\n",
    "- \\( b \\) = Number of cases with exposure and outcome absent\n",
    "- \\( c \\) = Number of cases without exposure and outcome present\n",
    "- \\( d \\) = Number of cases without exposure and outcome absent\n",
    "\n",
    "### Interpretation of the Odds Ratio\n",
    "\n",
    "- **Odds Ratio > 1**: Positive association between the variables.\n",
    "- **Odds Ratio = 1**: No association between the variables.\n",
    "- **Odds Ratio < 1**: Negative association between the variables.\n",
    "\n",
    "## Example: Chi-Square Test for Independence\n",
    "\n",
    "Using `Group` and `Purchase_Made` variables:\n",
    "\n",
    "- **Null Hypothesis (H0)**: No association between `Group` and `Purchase_Made`.\n",
    "- **Alternative Hypothesis (H1)**: An association exists between `Group` and `Purchase_Made`.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Create a Contingency Table**: Summarize the data.\n",
    "2. **Calculate the Chi-Square Statistic**: Use observed and expected frequencies.\n",
    "3. **Determine the p-value**: Compare the statistic to the Chi-Square distribution.\n",
    "4. **Interpret the Results**: Based on the p-value.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Chi-Square Statistic**: Measures the discrepancy between observed and expected frequencies.\n",
    "- **p-value**: Probability of observing the test results under the null hypothesis.\n",
    "- **Degrees of Freedom**: Calculated as (rows - 1) * (columns - 1).\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating a significant association. Otherwise, fail to reject the null hypothesis.\n",
    "\n",
    "### Odds Ratio Interpretation\n",
    "\n",
    "- **Odds Ratio > 1**: Positive association between `Group` and `Purchase_Made`.\n",
    "- **Odds Ratio = 1**: No association between `Group` and `Purchase_Made`.\n",
    "- **Odds Ratio < 1**: Negative association between `Group` and `Purchase_Made`.\n",
    "\n",
    "## Fisher's Exact Test\n",
    "\n",
    "Fisher's Exact Test is an alternative to the Chi-Square Test when the sample size is small, or the expected frequency assumption is not met. Though we meet the conditions for the Chi-Square Test in this example, we'll demonstrate Fisher's Exact Test for practice purposes. Note that Fisher's Exact Test is only applicable for 2x2 contingency tables.\n",
    "\n",
    "### Example: Fisher's Exact Test\n",
    "\n",
    "Using the same `Group` and `Purchase_Made` variables:\n",
    "\n",
    "- **Null Hypothesis (H0)**: No association between `Group` and `Purchase_Made`.\n",
    "- **Alternative Hypothesis (H1)**: An association exists between `Group` and `Purchase_Made`.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Create a Contingency Table**: Summarize the data.\n",
    "2. **Perform Fisher's Exact Test**: Calculate the exact p-value.\n",
    "3. **Interpret the Results**: Based on the p-value.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **p-value**: Provides the probability of observing the test results under the null hypothesis.\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating a significant association. Otherwise, fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585fa604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:40.225402Z",
     "iopub.status.busy": "2024-05-16T13:45:40.225027Z",
     "iopub.status.idle": "2024-05-16T13:45:42.033941Z",
     "shell.execute_reply": "2024-05-16T13:45:42.032682Z"
    },
    "papermill": {
     "duration": 1.81821,
     "end_time": "2024-05-16T13:45:42.036611",
     "exception": false,
     "start_time": "2024-05-16T13:45:40.218401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "Checking Assumptions...\n",
      "\n",
      "Contingency Table:\n",
      "Purchase_Made   No  Yes\n",
      "Group                  \n",
      "Control        248  252\n",
      "Treatment      237  263\n",
      "\n",
      "Expected Frequencies:\n",
      "Purchase_Made     No    Yes\n",
      "Group                      \n",
      "Control        242.5  257.5\n",
      "Treatment      242.5  257.5\n",
      "\n",
      "All expected frequencies are at least 5. Assumptions are satisfied.\n",
      "\n",
      "Chi-Square Test Results:\n",
      "Chi-Square Statistic: 0.4004\n",
      "p-value: 0.5269\n",
      "Degrees of Freedom: 1\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check the assumptions\n",
    "print(\"\\nChecking Assumptions...\")\n",
    "\n",
    "# Assumption 1: Random Sampling\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Assumption 2: Expected Frequency\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(sampled_data['Group'], sampled_data['Purchase_Made'])\n",
    "\n",
    "# Display the contingency table\n",
    "print(\"\\nContingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform the Chi-Square test and check the expected frequencies\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
    "\n",
    "# Check if all expected frequencies are at least 5\n",
    "if (expected < 5).any():\n",
    "    print(\"\\nWarning: Some expected frequencies are less than 5. Switching to Fisher's Exact Test.\")\n",
    "    \n",
    "    # Perform Fisher's Exact Test\n",
    "    if contingency_table.shape == (2, 2):\n",
    "        odds_ratio, fisher_p = stats.fisher_exact(contingency_table)\n",
    "        print(\"\\nFisher's Exact Test Results:\")\n",
    "        print(f\"Odds Ratio: {odds_ratio:.4f}\")\n",
    "        print(f\"p-value: {fisher_p:.4f}\")\n",
    "\n",
    "        # Interpret the p-value from Fisher's Exact Test\n",
    "        alpha = 0.05\n",
    "        print(f\"\\nSignificance Level: {alpha}\")\n",
    "        if fisher_p < alpha:\n",
    "            print(\"Conclusion: Reject the null hypothesis. There is a significant association between Group and Purchase_Made (Fisher's Exact Test).\")\n",
    "        else:\n",
    "            print(\"Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made (Fisher's Exact Test).\")\n",
    "    else:\n",
    "        print(\"\\nFisher's Exact Test is not applicable for this contingency table size.\")\n",
    "else:\n",
    "    print(\"\\nAll expected frequencies are at least 5. Assumptions are satisfied.\")\n",
    "    \n",
    "    # Display the results of the Chi-Square test\n",
    "    print(\"\\nChi-Square Test Results:\")\n",
    "    print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    print(f\"Degrees of Freedom: {dof}\")\n",
    "\n",
    "    # Interpret the p-value\n",
    "    alpha = 0.05\n",
    "    print(f\"\\nSignificance Level: {alpha}\")\n",
    "    if p < alpha:\n",
    "        print(\"Conclusion: Reject the null hypothesis. There is a significant association between Group and Purchase_Made.\")\n",
    "        \n",
    "        # Calculate the odds ratio for a 2x2 contingency table\n",
    "        if contingency_table.shape == (2, 2):\n",
    "            odds_ratio = (contingency_table.iloc[0, 0] * contingency_table.iloc[1, 1]) / (contingency_table.iloc[0, 1] * contingency_table.iloc[1, 0])\n",
    "            print(f\"\\nOdds Ratio: {odds_ratio:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nOdds Ratio calculation is only applicable for 2x2 contingency tables.\")\n",
    "    else:\n",
    "        print(\"Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902d6d9",
   "metadata": {
    "papermill": {
     "duration": 0.004715,
     "end_time": "2024-05-16T13:45:42.046475",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.041760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Independent Samples T-Test (Two-Sample T-Test)\n",
    "\n",
    "The Independent Samples T-Test, also known as the Two-Sample T-Test, determines whether there is a statistically significant difference between the means of two independent groups.\n",
    "\n",
    "## What is the Independent Samples T-Test?\n",
    "\n",
    "A parametric test that compares the means of two independent groups to see if they are significantly different from each other.\n",
    "\n",
    "## When to Use the Independent Samples T-Test\n",
    "\n",
    "- The dependent variable is continuous.\n",
    "- The independent variable consists of two categorical, independent groups.\n",
    "- Observations are independent of each other.\n",
    "- The dependent variable is approximately normally distributed in each group.\n",
    "- Homogeneity of variances: The variances in the two groups are equal.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. The dependent variable is normally distributed in each group.\n",
    "   - If normality is not met, consider using a non-parametric test such as the Mann-Whitney U Test.\n",
    "\n",
    "2. Homogeneity of variances.\n",
    "   - If homogeneity of variances is not met, use Welch's T-Test, which does not assume equal variances.\n",
    "\n",
    "\n",
    "## Hypotheses for Independent Samples T-Test\n",
    "\n",
    "- **Null Hypothesis (H0)**: The means of the two groups are equal.\n",
    "- **Alternative Hypothesis (H1)**: The means of the two groups are not equal.\n",
    "\n",
    "\n",
    "## Step-by-Step Guide\n",
    "\n",
    "1. **Check Assumptions**: Verify normality and homogeneity of variances.\n",
    "\n",
    "2. **Calculate the T-Test Statistic**:\n",
    "\n",
    "   $$\n",
    "   t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "   $$\n",
    "   \n",
    "   where \\(\\bar{X}_1\\) and \\(\\bar{X}_2\\) are the sample means, \\(s_1^2\\) and \\(s_2^2\\) are the sample variances, and \\(n_1\\) and \\(n_2\\) are the sample sizes.\n",
    "3. **Determine the p-value**: Compare the T-Test statistic to a t-distribution with degrees of freedom:\n",
    "\n",
    "   $$\n",
    "   df = \\frac{\\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}{\\frac{\\left( \\frac{s_1^2}{n_1} \\right)^2}{n_1 - 1} + \\frac{\\left( \\frac{s_2^2}{n_2} \\right)^2}{n_2 - 1}}\n",
    "   $$\n",
    "   \n",
    "4. **Interpret the Results**: If the p-value is â‰¤ 0.05, reject the null hypothesis.\n",
    "\n",
    "## Example: Independent Samples T-Test\n",
    "\n",
    "Using `Sales_Before` variable to compare `Control` and `Treatment` groups:\n",
    "\n",
    "- **Null Hypothesis (H0)**: The mean `Sales_Before` in the `Control` group is equal to the mean `Sales_Before` in the `Treatment` group.\n",
    "- **Alternative Hypothesis (H1)**: The mean `Sales_Before` in the `Control` group is not equal to the mean `Sales_Before` in the `Treatment` group.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Check Assumptions**: Verify normality and homogeneity of variances.\n",
    "2. **Calculate the T-Test Statistic**: Use the sample means, variances, and sizes.\n",
    "3. **Determine the p-value**: Compare the statistic to a t-distribution.\n",
    "4. **Interpret the Results**: Based on the p-value.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **T-Test Statistic**: Measures the difference between group means relative to the variability in the groups.\n",
    "- **p-value**: Probability of observing the test results under the null hypothesis.\n",
    "- **Degrees of Freedom**: Calculated using the formula above.\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating a significant difference between the means. Otherwise, fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d7dd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:42.058674Z",
     "iopub.status.busy": "2024-05-16T13:45:42.057649Z",
     "iopub.status.idle": "2024-05-16T13:45:42.096170Z",
     "shell.execute_reply": "2024-05-16T13:45:42.094505Z"
    },
    "papermill": {
     "duration": 0.047103,
     "end_time": "2024-05-16T13:45:42.098523",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.051420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "Checking Assumptions...\n",
      "\n",
      "Normality Test (Shapiro-Wilk):\n",
      "Control group p-value: 0.7610\n",
      "Treatment group p-value: 0.5947\n",
      "\n",
      "Homogeneity of Variances Test (Levene's Test):\n",
      "p-value: 0.9613\n",
      "\n",
      "Independent Samples T-Test Results:\n",
      "Test Statistic: -0.3620\n",
      "p-value: 0.7175\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Fail to reject the null hypothesis. There is no significant difference in Sales_Before between Control and Treatment groups (using Independent Samples T-Test).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Check assumptions\n",
    "print(\"\\nChecking Assumptions...\")\n",
    "\n",
    "# Extract relevant columns from the sampled data\n",
    "control_group = sampled_data[sampled_data['Group'] == 'Control']['Sales_Before']\n",
    "treatment_group = sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before']\n",
    "\n",
    "# Assumption 1: Normality\n",
    "control_normality = stats.shapiro(control_group)\n",
    "treatment_normality = stats.shapiro(treatment_group)\n",
    "\n",
    "print(\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "print(f\"Control group p-value: {control_normality.pvalue:.4f}\")\n",
    "print(f\"Treatment group p-value: {treatment_normality.pvalue:.4f}\")\n",
    "\n",
    "# Assumption 2: Homogeneity of variances\n",
    "levene_test = stats.levene(control_group, treatment_group)\n",
    "\n",
    "print(\"\\nHomogeneity of Variances Test (Levene's Test):\")\n",
    "print(f\"p-value: {levene_test.pvalue:.4f}\")\n",
    "\n",
    "# Perform the appropriate T-Test based on the assumptions\n",
    "if control_normality.pvalue > 0.05 and treatment_normality.pvalue > 0.05:\n",
    "    if levene_test.pvalue > 0.05:\n",
    "        # Perform the Independent Samples T-Test\n",
    "        t_stat, p_val = stats.ttest_ind(control_group, treatment_group, equal_var=True)\n",
    "        test_used = \"Independent Samples T-Test\"\n",
    "    else:\n",
    "        # Perform Welch's T-Test\n",
    "        t_stat, p_val = stats.ttest_ind(control_group, treatment_group, equal_var=False)\n",
    "        test_used = \"Welch's T-Test\"\n",
    "else:\n",
    "    # Perform the Mann-Whitney U Test\n",
    "    t_stat, p_val = stats.mannwhitneyu(control_group, treatment_group)\n",
    "    test_used = \"Mann-Whitney U Test\"\n",
    "\n",
    "# Display the results of the T-Test\n",
    "print(f\"\\n{test_used} Results:\")\n",
    "print(f\"Test Statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# Interpret the p-value\n",
    "alpha = 0.05\n",
    "print(f\"\\nSignificance Level: {alpha}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Conclusion: Reject the null hypothesis. There is a significant difference in Sales_Before between Control and Treatment groups (using {test_used}).\")\n",
    "else:\n",
    "    print(f\"Conclusion: Fail to reject the null hypothesis. There is no significant difference in Sales_Before between Control and Treatment groups (using {test_used}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c20d9",
   "metadata": {
    "papermill": {
     "duration": 0.004967,
     "end_time": "2024-05-16T13:45:42.108753",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.103786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Paired T-Test\n",
    "\n",
    "The Paired T-Test determines whether there is a statistically significant difference between the means of two related groups.\n",
    "\n",
    "## What is the Paired T-Test?\n",
    "\n",
    "A parametric test that compares the means of two related groups to see if they are significantly different from each other.\n",
    "\n",
    "## When to Use the Paired T-Test\n",
    "\n",
    "- The dependent variable is continuous.\n",
    "- The observations are paired or matched in some meaningful way.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. The differences between pairs are normally distributed.\n",
    "   - If normality is not met, use the Wilcoxon Signed-Rank Test.\n",
    "\n",
    "## Hypotheses for Paired T-Test\n",
    "\n",
    "- **Null Hypothesis (H0)**: The mean difference between the paired observations is zero.\n",
    "- **Alternative Hypothesis (H1)**: The mean difference between the paired observations is not zero.\n",
    "\n",
    "## Step-by-Step Guide\n",
    "\n",
    "1. **Check Assumptions**: Verify normality of the differences.\n",
    "2. **Calculate the T-Test Statistic**:\n",
    "\n",
    "   $$\n",
    "   t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n",
    "   $$\n",
    "   \n",
    "   where \\(\\bar{d}\\) is the mean of the differences, \\(s_d\\) is the standard deviation of the differences, and \\(n\\) is the number of pairs.\n",
    "3. **Determine the p-value**: Compare the T-Test statistic to a t-distribution with \\(n-1\\) degrees of freedom.\n",
    "4. **Interpret the Results**: If the p-value is â‰¤ 0.05, reject the null hypothesis.\n",
    "\n",
    "## Example: Paired T-Test\n",
    "\n",
    "Using `Sales_Before` and `Sales_After` variables:\n",
    "\n",
    "- **Null Hypothesis (H0)**: The mean difference between `Sales_Before` and `Sales_After` is zero.\n",
    "- **Alternative Hypothesis (H1)**: The mean difference between `Sales_Before` and `Sales_After` is not zero.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Check Assumptions**: Verify normality of the differences.\n",
    "2. **Perform the Paired T-Test**: Use the sample means, variances, and sizes.\n",
    "3. **Determine the p-value**: Compare the statistic to a t-distribution.\n",
    "4. **Interpret the Results**: Based on the p-value.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **T-Test Statistic**: Measures the difference between the paired means relative to the variability in the differences.\n",
    "- **p-value**: Probability of observing the test results under the null hypothesis.\n",
    "- **Degrees of Freedom**: \\(n - 1\\)\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating a significant difference between the paired means. Otherwise, fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e03260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:42.121065Z",
     "iopub.status.busy": "2024-05-16T13:45:42.120193Z",
     "iopub.status.idle": "2024-05-16T13:45:42.155715Z",
     "shell.execute_reply": "2024-05-16T13:45:42.154317Z"
    },
    "papermill": {
     "duration": 0.044303,
     "end_time": "2024-05-16T13:45:42.158172",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.113869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "Checking Assumptions...\n",
      "\n",
      "Normality Test (Shapiro-Wilk) for Differences:\n",
      "p-value: 0.0000\n",
      "\n",
      "Wilcoxon Signed-Rank Test Results:\n",
      "Test Statistic: 2.0000\n",
      "p-value: 0.0000\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Reject the null hypothesis. There is a significant difference between Sales_Before and Sales_After (using Wilcoxon Signed-Rank Test).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Extract relevant columns from the sampled data\n",
    "sales_before = sampled_data['Sales_Before']\n",
    "sales_after = sampled_data['Sales_After']\n",
    "\n",
    "# Check assumptions\n",
    "print(\"\\nChecking Assumptions...\")\n",
    "\n",
    "# Assumption: Normality of differences\n",
    "differences = sales_after - sales_before\n",
    "normality_test = stats.shapiro(differences)\n",
    "\n",
    "print(\"\\nNormality Test (Shapiro-Wilk) for Differences:\")\n",
    "print(f\"p-value: {normality_test.pvalue:.4f}\")\n",
    "\n",
    "# Perform the appropriate test based on the assumption\n",
    "if normality_test.pvalue > 0.05:\n",
    "    # Perform the Paired T-Test\n",
    "    t_stat, p_val = stats.ttest_rel(sales_before, sales_after)\n",
    "    test_used = \"Paired T-Test\"\n",
    "else:\n",
    "    # Perform the Wilcoxon Signed-Rank Test\n",
    "    t_stat, p_val = stats.wilcoxon(sales_before, sales_after)\n",
    "    test_used = \"Wilcoxon Signed-Rank Test\"\n",
    "\n",
    "# Display the results of the test\n",
    "print(f\"\\n{test_used} Results:\")\n",
    "print(f\"Test Statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# Interpret the p-value\n",
    "alpha = 0.05\n",
    "print(f\"\\nSignificance Level: {alpha}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Conclusion: Reject the null hypothesis. There is a significant difference between Sales_Before and Sales_After (using {test_used}).\")\n",
    "else:\n",
    "    print(f\"Conclusion: Fail to reject the null hypothesis. There is no significant difference between Sales_Before and Sales_After (using {test_used}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a123a4",
   "metadata": {
    "papermill": {
     "duration": 0.005022,
     "end_time": "2024-05-16T13:45:42.168644",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.163622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ANOVA (Analysis of Variance)\n",
    "\n",
    "The ANOVA test determines whether there are statistically significant differences between the means of three or more independent groups.\n",
    "\n",
    "## What is ANOVA?\n",
    "\n",
    "A parametric test that compares the means of three or more independent groups to see if at least one of the group means is significantly different from the others.\n",
    "\n",
    "## When to Use ANOVA\n",
    "\n",
    "- The dependent variable is continuous.\n",
    "- The independent variable consists of three or more categorical, independent groups.\n",
    "- Observations are independent of each other.\n",
    "- The dependent variable is approximately normally distributed in each group.\n",
    "- Homogeneity of variances: The variances in the groups are equal.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. The dependent variable is normally distributed in each group.\n",
    "   - If normality is not met, consider using a non-parametric test such as the Kruskal-Wallis Test.\n",
    "2. Homogeneity of variances.\n",
    "   - If homogeneity of variances is not met, use Welch's ANOVA.\n",
    "\n",
    "## Hypotheses for ANOVA\n",
    "\n",
    "- **Null Hypothesis (H0)**: All group means are equal.\n",
    "- **Alternative Hypothesis (H1)**: At least one group mean is different.\n",
    "\n",
    "## Step-by-Step Guide\n",
    "\n",
    "1. **Check Assumptions**: Verify normality and homogeneity of variances.\n",
    "2. **Calculate the ANOVA F-Statistic**:\n",
    "\n",
    "   $$\n",
    "   F = \\frac{\\text{between-group variability}}{\\text{within-group variability}}\n",
    "   $$\n",
    "\n",
    "3. **Determine the p-value**: Compare the F-Statistic to an F-distribution with appropriate degrees of freedom.\n",
    "4. **Interpret the Results**: If the p-value is â‰¤ 0.05, reject the null hypothesis.\n",
    "\n",
    "## Post Hoc Analysis\n",
    "\n",
    "If the ANOVA test indicates significant differences, conduct a post hoc analysis to identify which groups differ from each other.\n",
    "\n",
    "### Tukey's HSD Test\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test compares all possible pairs of group means to determine which groups are significantly different.\n",
    "\n",
    "## Example: ANOVA\n",
    "\n",
    "Using `Customer_Satisfaction_After` variable across different `Customer_Segment` categories:\n",
    "\n",
    "- **Null Hypothesis (H0)**: The mean `Customer_Satisfaction_After` is equal across all `Customer_Segment` categories.\n",
    "- **Alternative Hypothesis (H1)**: At least one mean `Customer_Satisfaction_After` is different across `Customer_Segment` categories.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Check Assumptions**: Verify normality and homogeneity of variances.\n",
    "2. **Perform ANOVA**: Use the sample means, variances, and sizes.\n",
    "3. **Determine the p-value**: Compare the statistic to an F-distribution.\n",
    "4. **Interpret the Results**: Based on the p-value.\n",
    "5. **Conduct Post Hoc Analysis**: If ANOVA is significant, perform Tukey's HSD test to determine which groups differ.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **ANOVA F-Statistic**: Measures the ratio of between-group variability to within-group variability.\n",
    "- **p-value**: Probability of observing the test results under the null hypothesis.\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating that at least one group mean is significantly different. Otherwise, fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c28833e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:42.180802Z",
     "iopub.status.busy": "2024-05-16T13:45:42.180393Z",
     "iopub.status.idle": "2024-05-16T13:45:44.296343Z",
     "shell.execute_reply": "2024-05-16T13:45:44.294989Z"
    },
    "papermill": {
     "duration": 2.124815,
     "end_time": "2024-05-16T13:45:44.298642",
     "exception": false,
     "start_time": "2024-05-16T13:45:42.173827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "Checking Assumptions...\n",
      "\n",
      "Normality Test (Shapiro-Wilk) for each group:\n",
      "Customer_Segment\n",
      "High Value      5.652129e-19\n",
      "Low Value       2.664373e-05\n",
      "Medium Value    1.415237e-05\n",
      "Name: Customer_Satisfaction_After, dtype: float64\n",
      "\n",
      "Homogeneity of Variances Test (Levene's Test):\n",
      "p-value: 0.0011\n",
      "\n",
      "Kruskal-Wallis Test Results:\n",
      "KruskalResult(statistic=487.16277968511116, pvalue=1.636614886093797e-106)\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Reject the null hypothesis. There is a significant difference in Customer_Satisfaction_After across different Customer_Segment categories (using Kruskal-Wallis Test).\n",
      "\n",
      "Performing Tukey's HSD Test...\n",
      "      Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
      "===============================================================\n",
      "  group1      group2    meandiff p-adj  lower    upper   reject\n",
      "---------------------------------------------------------------\n",
      "High Value    Low Value -30.6142   0.0 -33.0703 -28.1581   True\n",
      "High Value Medium Value -13.4769   0.0 -15.9254 -11.0283   True\n",
      " Low Value Medium Value  17.1373   0.0  14.6667  19.6079   True\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Extract relevant columns from the sampled data\n",
    "customer_satisfaction_after = sampled_data['Customer_Satisfaction_After']\n",
    "customer_segment = sampled_data['Customer_Segment']\n",
    "\n",
    "# Check assumptions\n",
    "print(\"\\nChecking Assumptions...\")\n",
    "\n",
    "# Assumption: Normality of each group\n",
    "groups = sampled_data.groupby('Customer_Segment')['Customer_Satisfaction_After']\n",
    "normality_p_values = groups.apply(lambda x: stats.shapiro(x)[1])\n",
    "print(\"\\nNormality Test (Shapiro-Wilk) for each group:\")\n",
    "print(normality_p_values)\n",
    "\n",
    "# Assumption: Homogeneity of variances\n",
    "levene_test = stats.levene(*[group for name, group in groups])\n",
    "print(\"\\nHomogeneity of Variances Test (Levene's Test):\")\n",
    "print(f\"p-value: {levene_test.pvalue:.4f}\")\n",
    "\n",
    "# Perform the appropriate ANOVA test based on the assumptions\n",
    "if all(normality_p_values > 0.05):\n",
    "    if levene_test.pvalue > 0.05:\n",
    "        # Perform ANOVA\n",
    "        model = ols('Customer_Satisfaction_After ~ C(Customer_Segment)', data=sampled_data).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        # Perform Welch's ANOVA\n",
    "        model = ols('Customer_Satisfaction_After ~ C(Customer_Segment)', data=sampled_data).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2, robust='hc3')\n",
    "        test_used = \"Welch's ANOVA\"\n",
    "else:\n",
    "    # Perform Kruskal-Wallis Test\n",
    "    kruskal_test = stats.kruskal(*[group for name, group in groups])\n",
    "    anova_table = kruskal_test\n",
    "    test_used = \"Kruskal-Wallis Test\"\n",
    "\n",
    "# Display the results of the ANOVA test\n",
    "print(f\"\\n{test_used} Results:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the p-value\n",
    "alpha = 0.05\n",
    "if test_used == \"Kruskal-Wallis Test\":\n",
    "    p_val = anova_table.pvalue\n",
    "else:\n",
    "    p_val = anova_table['PR(>F)'][0]\n",
    "\n",
    "print(f\"\\nSignificance Level: {alpha}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Conclusion: Reject the null hypothesis. There is a significant difference in Customer_Satisfaction_After across different Customer_Segment categories (using {test_used}).\")\n",
    "    \n",
    "    # Perform Post Hoc Analysis using Tukey's HSD Test\n",
    "    print(\"\\nPerforming Tukey's HSD Test...\")\n",
    "    tukey = pairwise_tukeyhsd(endog=sampled_data['Customer_Satisfaction_After'], groups=sampled_data['Customer_Segment'], alpha=0.05)\n",
    "    print(tukey)\n",
    "else:\n",
    "    print(f\"Conclusion: Fail to reject the null hypothesis. There is no significant difference in Customer_Satisfaction_After across different Customer_Segment categories (using {test_used}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cbac4",
   "metadata": {
    "papermill": {
     "duration": 0.00531,
     "end_time": "2024-05-16T13:45:44.309546",
     "exception": false,
     "start_time": "2024-05-16T13:45:44.304236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Correlation Test\n",
    "\n",
    "The correlation test determines the strength and direction of the linear relationship between two continuous variables.\n",
    "\n",
    "## What is a Correlation Test?\n",
    "\n",
    "A statistical method used to assess the strength and direction of the linear relationship between two continuous variables.\n",
    "\n",
    "## When to Use a Correlation Test\n",
    "\n",
    "- Both variables are continuous.\n",
    "- The relationship between the variables is linear.\n",
    "- Data pairs are independent of each other.\n",
    "\n",
    "## Types of Correlation Tests\n",
    "\n",
    "1. **Pearson Correlation**: Measures the linear relationship between two continuous variables. Assumes both variables are normally distributed.\n",
    "   - If normality is not met, use Spearman's Rank Correlation.\n",
    "2. **Spearman's Rank Correlation**: Measures the monotonic relationship between two continuous or ordinal variables.\n",
    "\n",
    "## Hypotheses for Correlation Test\n",
    "\n",
    "- **Null Hypothesis (H0)**: There is no correlation between the variables.\n",
    "- **Alternative Hypothesis (H1)**: There is a correlation between the variables.\n",
    "\n",
    "## Step-by-Step Guide\n",
    "\n",
    "1. **Check Assumptions**: Verify normality of both variables.\n",
    "   - If normality is not met, use Spearman's Rank Correlation.\n",
    "2. **Calculate the Correlation Coefficient**:\n",
    "\n",
    "   $$\n",
    "   r = \\frac{n(\\sum xy) - (\\sum x)(\\sum y)}{\\sqrt{[n \\sum x^2 - (\\sum x)^2][n \\sum y^2 - (\\sum y)^2]}}\n",
    "   $$\n",
    "\n",
    "3. **Determine the p-value**: Compare the correlation coefficient to a t-distribution.\n",
    "4. **Interpret the Results**: If the p-value is â‰¤ 0.05, reject the null hypothesis.\n",
    "\n",
    "## Example: Correlation Test\n",
    "\n",
    "Using `Sales_Before` and `Sales_After` variables:\n",
    "\n",
    "- **Null Hypothesis (H0)**: There is no correlation between `Sales_Before` and `Sales_After`.\n",
    "- **Alternative Hypothesis (H1)**: There is a correlation between `Sales_Before` and `Sales_After`.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Check Assumptions**: Verify normality of both variables.\n",
    "2. **Perform the Correlation Test**: Use the sample means, variances, and sizes.\n",
    "3. **Determine the p-value**: Compare the statistic to a t-distribution.\n",
    "4. **Interpret the Results**: Based on the p-value.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Correlation Coefficient (r)**: Measures the strength and direction of the linear relationship between the variables.\n",
    "- **p-value**: Probability of observing the test results under the null hypothesis.\n",
    "\n",
    "If the p-value is < 0.05, reject the null hypothesis, indicating a significant correlation between the variables. Otherwise, fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c0643d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:44.322013Z",
     "iopub.status.busy": "2024-05-16T13:45:44.321572Z",
     "iopub.status.idle": "2024-05-16T13:45:44.359422Z",
     "shell.execute_reply": "2024-05-16T13:45:44.358276Z"
    },
    "papermill": {
     "duration": 0.047363,
     "end_time": "2024-05-16T13:45:44.362263",
     "exception": false,
     "start_time": "2024-05-16T13:45:44.314900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "Checking Assumptions...\n",
      "\n",
      "Normality Test (Shapiro-Wilk):\n",
      "Sales_Before p-value: 0.4559\n",
      "Sales_After p-value: 0.0004\n",
      "\n",
      "Spearman's Rank Correlation Results:\n",
      "Correlation Coefficient: 0.8737\n",
      "p-value: 0.0000\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Reject the null hypothesis. There is a significant correlation between Sales_Before and Sales_After (using Spearman's Rank Correlation).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Extract relevant columns from the sampled data\n",
    "sales_before = sampled_data['Sales_Before']\n",
    "sales_after = sampled_data['Sales_After']\n",
    "\n",
    "# Check assumptions\n",
    "print(\"\\nChecking Assumptions...\")\n",
    "\n",
    "# Assumption: Normality of both variables\n",
    "normality_test_before = stats.shapiro(sales_before)\n",
    "normality_test_after = stats.shapiro(sales_after)\n",
    "\n",
    "print(\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "print(f\"Sales_Before p-value: {normality_test_before.pvalue:.4f}\")\n",
    "print(f\"Sales_After p-value: {normality_test_after.pvalue:.4f}\")\n",
    "\n",
    "# Perform the appropriate correlation test based on the assumptions\n",
    "if normality_test_before.pvalue > 0.05 and normality_test_after.pvalue > 0.05:\n",
    "    # Perform Pearson Correlation\n",
    "    correlation_coefficient, p_val = stats.pearsonr(sales_before, sales_after)\n",
    "    test_used = \"Pearson Correlation\"\n",
    "else:\n",
    "    # Perform Spearman's Rank Correlation\n",
    "    correlation_coefficient, p_val = stats.spearmanr(sales_before, sales_after)\n",
    "    test_used = \"Spearman's Rank Correlation\"\n",
    "\n",
    "# Display the results of the correlation test\n",
    "print(f\"\\n{test_used} Results:\")\n",
    "print(f\"Correlation Coefficient: {correlation_coefficient:.4f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# Interpret the p-value\n",
    "alpha = 0.05\n",
    "print(f\"\\nSignificance Level: {alpha}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Conclusion: Reject the null hypothesis. There is a significant correlation between Sales_Before and Sales_After (using {test_used}).\")\n",
    "else:\n",
    "    print(f\"Conclusion: Fail to reject the null hypothesis. There is no significant correlation between Sales_Before and Sales_After (using {test_used}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8086a8",
   "metadata": {
    "papermill": {
     "duration": 0.005466,
     "end_time": "2024-05-16T13:45:44.373888",
     "exception": false,
     "start_time": "2024-05-16T13:45:44.368422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A/B Testing (Continuous & Boolean Outcomes)\n",
    "\n",
    "A/B testing, also known as split testing, is a method to compare two versions of a variable to determine which one performs better. It is commonly used in marketing, user experience research, and product development.\n",
    "\n",
    "## What is A/B Testing?\n",
    "\n",
    "A/B testing involves randomly splitting a sample into two groups:\n",
    "- **Control Group**: Does not receive the treatment.\n",
    "- **Treatment Group**: Receives the treatment.\n",
    "\n",
    "The goal is to determine if there is a statistically significant difference between the two groups.\n",
    "\n",
    "## Continuous Outcomes\n",
    "\n",
    "When the outcome is continuous, such as sales or scores, we use statistical tests like the independent samples t-test to compare the means of the two groups.\n",
    "\n",
    "### Assumptions for Continuous Outcomes\n",
    "\n",
    "1. **Independence**: Observations are independent of each other.\n",
    "2. **Normality**: The data follows a normal distribution.\n",
    "   - If normality is not met, use a non-parametric test like the Mann-Whitney U test.\n",
    "3. **Homogeneity of Variances**: Variances of the two groups are equal.\n",
    "   - If variances are not equal, use Welchâ€™s t-test.\n",
    "\n",
    "## Boolean Outcomes\n",
    "\n",
    "When the outcome is boolean (yes/no), we use the Chi-Square test for independence or Fisher's Exact test to compare the proportions of the two groups.\n",
    "\n",
    "### Assumptions for Boolean Outcomes\n",
    "\n",
    "1. **Independence**: Observations are independent of each other.\n",
    "2. **Expected Frequency**: Each expected frequency should be at least 5.\n",
    "   - If expected frequencies are less than 5, use Fisher's Exact Test.\n",
    "\n",
    "## Step-by-Step Guide for A/B Testing\n",
    "\n",
    "### Continuous Outcomes\n",
    "\n",
    "1. **Check Assumptions**:\n",
    "   - **Normality**: Use Shapiro-Wilk test.\n",
    "   - **Homogeneity of Variances**: Use Leveneâ€™s test.\n",
    "2. **Perform the Appropriate Test**:\n",
    "   - **t-test**: If normality and homogeneity of variances are met.\n",
    "   - **Welchâ€™s t-test**: If variances are not equal.\n",
    "   - **Mann-Whitney U test**: If normality is not met.\n",
    "3. **Interpret Results**: Compare the p-value to the significance level (Î± = 0.05).\n",
    "\n",
    "### Boolean Outcomes\n",
    "\n",
    "1. **Create a Contingency Table**: Summarize the data.\n",
    "2. **Perform the Appropriate Test**:\n",
    "   - **Chi-Square Test**: If expected frequencies are at least 5.\n",
    "   - **Fisher's Exact Test**: If expected frequencies are less than 5.\n",
    "3. **Interpret Results**: Compare the p-value to the significance level (Î± = 0.05).\n",
    "\n",
    "### Example: A/B Testing\n",
    "\n",
    "Using `Sales_Before` and `Sales_After` for continuous outcomes and `Purchase_Made` for boolean outcomes.\n",
    "\n",
    "#### Continuous Outcomes\n",
    "\n",
    "- **Null Hypothesis (H0)**: No difference in `Sales_Before` between Control and Treatment groups.\n",
    "- **Alternative Hypothesis (H1)**: Difference in `Sales_Before` between Control and Treatment groups.\n",
    "\n",
    "#### Boolean Outcomes\n",
    "\n",
    "- **Null Hypothesis (H0)**: No association between `Group` and `Purchase_Made`.\n",
    "- **Alternative Hypothesis (H1)**: Association between `Group` and `Purchase_Made`.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Continuous Outcomes**: Based on the chosen test's p-value.\n",
    "- **Boolean Outcomes**: Based on the chosen test's p-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15aaa96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T13:45:44.387544Z",
     "iopub.status.busy": "2024-05-16T13:45:44.387147Z",
     "iopub.status.idle": "2024-05-16T13:45:44.444724Z",
     "shell.execute_reply": "2024-05-16T13:45:44.443546Z"
    },
    "papermill": {
     "duration": 0.067554,
     "end_time": "2024-05-16T13:45:44.447161",
     "exception": false,
     "start_time": "2024-05-16T13:45:44.379607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "       Group Customer_Segment  Sales_Before  Sales_After  \\\n",
      "0    Control       High Value    240.548359   300.007568   \n",
      "1  Treatment       High Value    246.862114   381.337555   \n",
      "2    Control       High Value    156.978084   179.330464   \n",
      "3    Control     Medium Value    192.126708   229.278031   \n",
      "4    Control       High Value    229.685623   270.167701   \n",
      "\n",
      "   Customer_Satisfaction_Before  Customer_Satisfaction_After Purchase_Made  \n",
      "0                     74.684767                    74.093658            No  \n",
      "1                    100.000000                   100.000000           Yes  \n",
      "2                     98.780735                   100.000000            No  \n",
      "3                     49.333766                    39.811841           Yes  \n",
      "4                     83.974852                    87.738591           Yes  \n",
      "\n",
      "A/B Testing for Continuous Outcomes...\n",
      "\n",
      "Normality Test (Shapiro-Wilk):\n",
      "Control group p-value: 0.7610\n",
      "Treatment group p-value: 0.5947\n",
      "\n",
      "Homogeneity of Variances Test (Levene's Test):\n",
      "p-value: 0.9613\n",
      "\n",
      "Independent Samples T-Test Results:\n",
      "Test Statistic: -0.3620\n",
      "p-value: 0.7175\n",
      "\n",
      "Significance Level: 0.05\n",
      "Conclusion: Fail to reject the null hypothesis. There is no significant difference in Sales_Before between Control and Treatment groups (using Independent Samples T-Test).\n",
      "\n",
      "A/B Testing for Boolean Outcomes...\n",
      "\n",
      "Contingency Table:\n",
      "Purchase_Made   No  Yes\n",
      "Group                  \n",
      "Control        248  252\n",
      "Treatment      237  263\n",
      "\n",
      "Expected Frequencies:\n",
      "Purchase_Made     No    Yes\n",
      "Group                      \n",
      "Control        242.5  257.5\n",
      "Treatment      242.5  257.5\n",
      "\n",
      "All expected frequencies are at least 5. Assumptions are satisfied.\n",
      "\n",
      "Chi-Square Test Results:\n",
      "Chi-Square Statistic: 0.4004\n",
      "p-value: 0.5269\n",
      "Degrees of Freedom: 1\n",
      "Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made (using Chi-Square Test).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/kaggle/input/sales-and-satisfaction/Sales_without_NaNs_v1.3.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Sample the dataset to reduce size for computation\n",
    "sampled_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "# Extract relevant columns from the sampled data\n",
    "group = sampled_data['Group']\n",
    "sales_before = sampled_data['Sales_Before']\n",
    "sales_after = sampled_data['Sales_After']\n",
    "purchase_made = sampled_data['Purchase_Made']\n",
    "\n",
    "# Continuous Outcomes\n",
    "print(\"\\nA/B Testing for Continuous Outcomes...\")\n",
    "\n",
    "# Assumption: Normality\n",
    "normality_test_control = stats.shapiro(sampled_data[sampled_data['Group'] == 'Control']['Sales_Before'])\n",
    "normality_test_treatment = stats.shapiro(sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before'])\n",
    "\n",
    "print(\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "print(f\"Control group p-value: {normality_test_control.pvalue:.4f}\")\n",
    "print(f\"Treatment group p-value: {normality_test_treatment.pvalue:.4f}\")\n",
    "\n",
    "# Assumption: Homogeneity of Variances\n",
    "levene_test = stats.levene(sampled_data[sampled_data['Group'] == 'Control']['Sales_Before'],\n",
    "                           sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before'])\n",
    "\n",
    "print(\"\\nHomogeneity of Variances Test (Levene's Test):\")\n",
    "print(f\"p-value: {levene_test.pvalue:.4f}\")\n",
    "\n",
    "# Perform the appropriate test based on the assumptions\n",
    "if normality_test_control.pvalue > 0.05 and normality_test_treatment.pvalue > 0.05:\n",
    "    if levene_test.pvalue > 0.05:\n",
    "        # Perform Independent Samples T-Test\n",
    "        t_stat, p_val = stats.ttest_ind(sampled_data[sampled_data['Group'] == 'Control']['Sales_Before'],\n",
    "                                        sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before'])\n",
    "        test_used = \"Independent Samples T-Test\"\n",
    "    else:\n",
    "        # Perform Welch's T-Test\n",
    "        t_stat, p_val = stats.ttest_ind(sampled_data[sampled_data['Group'] == 'Control']['Sales_Before'],\n",
    "                                        sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before'], equal_var=False)\n",
    "        test_used = \"Welch's T-Test\"\n",
    "else:\n",
    "    # Perform Mann-Whitney U Test\n",
    "    t_stat, p_val = stats.mannwhitneyu(sampled_data[sampled_data['Group'] == 'Control']['Sales_Before'],\n",
    "                                       sampled_data[sampled_data['Group'] == 'Treatment']['Sales_Before'])\n",
    "    test_used = \"Mann-Whitney U Test\"\n",
    "\n",
    "# Display the results of the continuous outcomes test\n",
    "print(f\"\\n{test_used} Results:\")\n",
    "print(f\"Test Statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# Interpret the p-value\n",
    "alpha = 0.05\n",
    "print(f\"\\nSignificance Level: {alpha}\")\n",
    "if p_val < alpha:\n",
    "    print(f\"Conclusion: Reject the null hypothesis. There is a significant difference in Sales_Before between Control and Treatment groups (using {test_used}).\")\n",
    "else:\n",
    "    print(f\"Conclusion: Fail to reject the null hypothesis. There is no significant difference in Sales_Before between Control and Treatment groups (using {test_used}).\")\n",
    "\n",
    "# Boolean Outcomes\n",
    "print(\"\\nA/B Testing for Boolean Outcomes...\")\n",
    "\n",
    "# Create a Contingency Table\n",
    "contingency_table = pd.crosstab(sampled_data['Group'], sampled_data['Purchase_Made'])\n",
    "\n",
    "# Display the contingency table\n",
    "print(\"\\nContingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform the appropriate test based on the assumptions\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
    "\n",
    "if (expected < 5).any():\n",
    "    print(\"\\nWarning: Some expected frequencies are less than 5. Switching to Fisher's Exact Test.\")\n",
    "    if contingency_table.shape == (2, 2):\n",
    "        odds_ratio, fisher_p = stats.fisher_exact(contingency_table)\n",
    "        print(\"\\nFisher's Exact Test Results:\")\n",
    "        print(f\"Odds Ratio: {odds_ratio:.4f}\")\n",
    "        print(f\"p-value: {fisher_p:.4f}\")\n",
    "\n",
    "        # Interpret the p-value from Fisher's Exact Test\n",
    "        if fisher_p < alpha:\n",
    "            print(\"Conclusion: Reject the null hypothesis. There is a significant association between Group and Purchase_Made (using Fisher's Exact Test).\")\n",
    "        else:\n",
    "            print(\"Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made (using Fisher's Exact Test).\")\n",
    "    else:\n",
    "        print(\"\\nFisher's Exact Test is not applicable for this contingency table size.\")\n",
    "else:\n",
    "    print(\"\\nAll expected frequencies are at least 5. Assumptions are satisfied.\")\n",
    "    \n",
    "    # Display the results of the Chi-Square test\n",
    "    print(\"\\nChi-Square Test Results:\")\n",
    "    print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    print(f\"Degrees of Freedom: {dof}\")\n",
    "\n",
    "    # Interpret the p-value\n",
    "    if p < alpha:\n",
    "        print(\"Conclusion: Reject the null hypothesis. There is a significant association between Group and Purchase_Made (using Chi-Square Test).\")\n",
    "    else:\n",
    "        print(\"Conclusion: Fail to reject the null hypothesis. There is no significant association between Group and Purchase_Made (using Chi-Square Test).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46553c5a",
   "metadata": {
    "papermill": {
     "duration": 0.006338,
     "end_time": "2024-05-16T13:45:44.459454",
     "exception": false,
     "start_time": "2024-05-16T13:45:44.453116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Thank You for Exploring This Notebook!\n",
    "\n",
    "\n",
    "If you have any questions, suggestions, or just want to discuss any of the topics further, please don't hesitate to reach out or leave a comment. Your feedback is not only welcome but also invaluable!\n",
    "\n",
    "Happy analyzing, and stay curious!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5003639,
     "sourceId": 8412638,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.001329,
   "end_time": "2024-05-16T13:45:45.090678",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T13:45:37.089349",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
