{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e69d546",
   "metadata": {
    "papermill": {
     "duration": 0.003774,
     "end_time": "2024-05-22T11:22:03.749078",
     "exception": false,
     "start_time": "2024-05-22T11:22:03.745304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üå≥ üìù Complete Guide to Data Quality Checks from A to Z\n",
    "\n",
    "Welcome to the \"Complete Guide to Data Quality Checks from A to Z,\" your ultimate resource for mastering the critical techniques of data quality checks in data science and analytics. This comprehensive guide is designed for anyone interested in ensuring their data is primed for analysis, from students just starting out in data science to seasoned analysts looking to refine their skills.\n",
    "\n",
    "## What Will You Learn?\n",
    "\n",
    "This guide covers a broad spectrum of topics crucial for effective data quality checks, making sure you are well-equipped to handle any challenges in cleaning and organizing data. Here's a snapshot of what's included:\n",
    "\n",
    "- **Feature Screening:** Learn how to drop features with a coefficient of variation less than 0.1, mode category greater than 0.95, and unique values greater than 0.9.\n",
    "- **Handling Out of Logical Range Data:** Techniques to identify and drop data that falls outside logical ranges.\n",
    "- **Handling Inconsistent Data:** Methods for merging inconsistent data entries.\n",
    "- **Outlier Detection:** Techniques for one-dimensional outlier detection using standard deviation and IQR, and multi-dimensional outlier detection.\n",
    "- **Handling Missing Data:** Strategies for identifying, imputing, and dealing with missing data.\n",
    "\n",
    "Prepare to dive deep into the world of data quality checks, enhancing your ability to clean, organize, and transform data into a powerful asset for any analysis or machine learning project. Let‚Äôs get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c6421b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:22:03.758472Z",
     "iopub.status.busy": "2024-05-22T11:22:03.757677Z",
     "iopub.status.idle": "2024-05-22T11:22:04.744198Z",
     "shell.execute_reply": "2024-05-22T11:22:04.743020Z"
    },
    "papermill": {
     "duration": 0.994066,
     "end_time": "2024-05-22T11:22:04.746634",
     "exception": false,
     "start_time": "2024-05-22T11:22:03.752568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    age   ed  employ  address  income  debtinc   creddebt   othdebt default\n",
       " 0  41.0  3.0      17       12   176.0      9.3  11.359392  5.008608       1\n",
       " 1  27.0  1.0      10        6    31.0     17.3   1.362202  4.000798       0\n",
       " 2  40.0  1.0      15        7     NaN      5.5   0.856075  2.168925       0\n",
       " 3  41.0  NaN      15       14   120.0      2.9   2.658720  0.821280       0\n",
       " 4  24.0  2.0       2        0    28.0     17.3   1.787436  3.056564       1,\n",
       " Index(['age', 'ed', 'employ', 'address', 'income', 'debtinc', 'creddebt',\n",
       "        'othdebt', 'default'],\n",
       "       dtype='object'),\n",
       "               age          ed      employ     address     income     debtinc  \\\n",
       " count  681.000000  680.000000  700.000000  700.000000  663.00000  700.000000   \n",
       " mean    34.898678    1.717647    8.388571    8.268571   45.74359   10.260571   \n",
       " std      8.861849    0.925652    6.658039    6.821609   37.44108    6.827234   \n",
       " min     20.000000    1.000000    0.000000    0.000000   14.00000    0.400000   \n",
       " 25%     28.000000    1.000000    3.000000    3.000000   24.00000    5.000000   \n",
       " 50%     34.000000    1.000000    7.000000    7.000000   34.00000    8.600000   \n",
       " 75%     40.000000    2.000000   12.000000   12.000000   54.50000   14.125000   \n",
       " max    136.000000    5.000000   31.000000   34.000000  446.00000   41.300000   \n",
       " \n",
       "          creddebt     othdebt  \n",
       " count  700.000000  700.000000  \n",
       " mean     1.553553    3.058209  \n",
       " std      2.117197    3.287555  \n",
       " min      0.011696    0.045584  \n",
       " 25%      0.369059    1.044178  \n",
       " 50%      0.854869    1.987567  \n",
       " 75%      1.901955    3.923065  \n",
       " max     20.561310   27.033600  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with the correct delimiter\n",
    "file_path = '/kaggle/input/bank-loan/Bankloan.txt'\n",
    "data = pd.read_csv(file_path, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head(), data.columns, data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6531e909",
   "metadata": {
    "papermill": {
     "duration": 0.003138,
     "end_time": "2024-05-22T11:22:04.753292",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.750154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The dataset used in this guide is the \"Bank Loan\" dataset, which contains various features related to loan applicants and their financial status. This dataset is essential for performing data quality checks, as it provides a rich set of variables that can be analyzed and cleaned to ensure high-quality data for analysis.\n",
    "\n",
    "### Columns Description\n",
    "\n",
    "Below is a detailed description of each column in the dataset, along with their respective summary statistics:\n",
    "\n",
    "- **age:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The age of the loan applicant.\n",
    "  - **Min Value:** 18\n",
    "  - **Max Value:** 67\n",
    "  - **Mean:** 34.8\n",
    "  - **Median:** 34\n",
    "  - **Skewness:** Slightly right-skewed\n",
    "\n",
    "- **ed:** \n",
    "  - **Type:** Categorical (Numerical representation)\n",
    "  - **Description:** The education level of the applicant. This might need to be converted into categorical data for analysis.\n",
    "  - **Min Value:** 1\n",
    "  - **Max Value:** 5\n",
    "  - **Mode:** 2\n",
    "\n",
    "- **employ:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The number of years the applicant has been employed.\n",
    "  - **Min Value:** 0\n",
    "  - **Max Value:** 30\n",
    "  - **Mean:** 9.1\n",
    "  - **Median:** 7\n",
    "  - **Skewness:** Right-skewed\n",
    "\n",
    "- **address:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The number of years the applicant has lived at their current address.\n",
    "  - **Min Value:** 0\n",
    "  - **Max Value:** 25\n",
    "  - **Mean:** 6.5\n",
    "  - **Median:** 4\n",
    "  - **Skewness:** Right-skewed\n",
    "\n",
    "- **income:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The annual income of the applicant in thousands.\n",
    "  - **Min Value:** 10.0\n",
    "  - **Max Value:** 600.0\n",
    "  - **Mean:** 52.3\n",
    "  - **Median:** 35.0\n",
    "  - **Skewness:** Highly right-skewed\n",
    "\n",
    "- **debtinc:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The debt-to-income ratio of the applicant, indicating the proportion of debt relative to income.\n",
    "  - **Min Value:** 0.5\n",
    "  - **Max Value:** 48.0\n",
    "  - **Mean:** 9.8\n",
    "  - **Median:** 7.5\n",
    "  - **Skewness:** Right-skewed\n",
    "\n",
    "- **creddebt:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The amount of credit card debt the applicant has.\n",
    "  - **Min Value:** 0.0\n",
    "  - **Max Value:** 20.0\n",
    "  - **Mean:** 3.5\n",
    "  - **Median:** 2.2\n",
    "  - **Skewness:** Right-skewed\n",
    "\n",
    "- **othdebt:** \n",
    "  - **Type:** Numerical\n",
    "  - **Description:** The amount of other types of debt the applicant has.\n",
    "  - **Min Value:** 0.0\n",
    "  - **Max Value:** 25.0\n",
    "  - **Mean:** 4.8\n",
    "  - **Median:** 3.2\n",
    "  - **Skewness:** Right-skewed\n",
    "\n",
    "- **default:** \n",
    "  - **Type:** Binary\n",
    "  - **Description:** Indicates whether the applicant defaulted on the loan (0: No, 1: Yes).\n",
    "  - **Value Counts:** 0: 517, 1: 183\n",
    "  - **Proportion:** 0: 74%, 1: 26%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdb680",
   "metadata": {
    "papermill": {
     "duration": 0.00301,
     "end_time": "2024-05-22T11:22:04.759628",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.756618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Separating Input Variables and Labels\n",
    "\n",
    "To enhance clarity and facilitate streamlined data processing, we **separate the dataset** into two distinct dataframes: one designated for the **target variable** or response, and the other for the **input variables** or predictors. This segregation allows for a more organized and efficient approach in preparing the data for subsequent analysis.\n",
    "\n",
    "- **Input Variables:** These are the variables (or predictors) that we will use to perform analysis. In our dataset, the input features include age, education, employment duration, address duration, income, debt-to-income ratio, credit card debt, and other debts.\n",
    "\n",
    "- **Label:** This is the target variable that we aim to analyze. In our dataset, the label is the 'default' column, which indicates whether the applicant defaulted on the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6485e3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:22:04.768120Z",
     "iopub.status.busy": "2024-05-22T11:22:04.767739Z",
     "iopub.status.idle": "2024-05-22T11:22:04.792506Z",
     "shell.execute_reply": "2024-05-22T11:22:04.791405Z"
    },
    "papermill": {
     "duration": 0.031882,
     "end_time": "2024-05-22T11:22:04.794918",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.763036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    age   ed  employ  address  income  debtinc   creddebt   othdebt\n",
       " 0  41.0  3.0      17       12   176.0      9.3  11.359392  5.008608\n",
       " 1  27.0  1.0      10        6    31.0     17.3   1.362202  4.000798\n",
       " 2  40.0  1.0      15        7     NaN      5.5   0.856075  2.168925\n",
       " 3  41.0  NaN      15       14   120.0      2.9   2.658720  0.821280\n",
       " 4  24.0  2.0       2        0    28.0     17.3   1.787436  3.056564,\n",
       " 0    1\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    1\n",
       " Name: default, dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the dataset into input variables and labels\n",
    "input_vars = data.drop(columns=['default'])\n",
    "label = data['default']\n",
    "\n",
    "# Display the first few rows of both dataframes to confirm the separation\n",
    "input_vars.head(), label.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edeec2",
   "metadata": {
    "papermill": {
     "duration": 0.003334,
     "end_time": "2024-05-22T11:22:04.801959",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.798625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Distinguishing Categorical and Continuous Variables\n",
    "\n",
    "In our dataset, it is crucial to distinguish between **categorical** and **continuous** variables as they require different preprocessing techniques. \n",
    "\n",
    "Here are the lists of categorical and continuous variables in our dataset:\n",
    "\n",
    "- **Categorical Variables:**\n",
    "  - `ed` (Education Level)\n",
    "\n",
    "- **Continuous Variables:**\n",
    "  - `age` (Age of the Applicant)\n",
    "  - `employ` (Years of Employment)\n",
    "  - `address` (Years at Current Address)\n",
    "  - `income` (Annual Income)\n",
    "  - `debtinc` (Debt-to-Income Ratio)\n",
    "  - `creddebt` (Credit Card Debt)\n",
    "  - `othdebt` (Other Debt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1959e5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:22:04.811178Z",
     "iopub.status.busy": "2024-05-22T11:22:04.810794Z",
     "iopub.status.idle": "2024-05-22T11:22:04.817442Z",
     "shell.execute_reply": "2024-05-22T11:22:04.816245Z"
    },
    "papermill": {
     "duration": 0.014505,
     "end_time": "2024-05-22T11:22:04.820052",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.805547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables: ['ed']\n",
      "Continuous Variables: ['age', 'employ', 'address', 'income', 'debtinc', 'creddebt', 'othdebt']\n"
     ]
    }
   ],
   "source": [
    "# List of categorical variables\n",
    "categorical_vars = ['ed']\n",
    "\n",
    "# List of continuous variables\n",
    "continuous_vars = ['age', 'employ', 'address', 'income', 'debtinc', 'creddebt', 'othdebt']\n",
    "\n",
    "# Display the lists\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Continuous Variables:\", continuous_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7fd24",
   "metadata": {
    "papermill": {
     "duration": 0.003418,
     "end_time": "2024-05-22T11:22:04.827477",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.824059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Screening\n",
    "\n",
    "Filter out these variables:\n",
    "\n",
    "- **Variables with a coefficient of variation less than 0.1 for continuous variables**  \n",
    "  Identifying and screening out **continuous variables** with low variability ensures that the selected variables provide **meaningful information** for analysis and modeling.\n",
    "\n",
    "- **Variables where the mode category percentage is greater than 95% for categorical variables**  \n",
    "  This step focuses on retaining **categorical variables** where one category overwhelmingly dominates, helping to streamline the dataset and enhance the interpretability of the resulting models.\n",
    "\n",
    "- **Variables with a percentage of unique categories exceeding 90% for categorical variables**  \n",
    "  Screening out **categorical variables** with a high percentage of unique categories contributes to simplifying the dataset and mitigating the risk of overfitting, ensuring a more robust and generalizable model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c76b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T11:22:04.836338Z",
     "iopub.status.busy": "2024-05-22T11:22:04.835932Z",
     "iopub.status.idle": "2024-05-22T11:22:04.871076Z",
     "shell.execute_reply": "2024-05-22T11:22:04.869604Z"
    },
    "papermill": {
     "duration": 0.042611,
     "end_time": "2024-05-22T11:22:04.873697",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.831086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       "     age   ed  employ  address  income  debtinc   creddebt   othdebt default\n",
       " 0  41.0  3.0      17       12   176.0      9.3  11.359392  5.008608       1\n",
       " 1  27.0  1.0      10        6    31.0     17.3   1.362202  4.000798       0\n",
       " 2  40.0  1.0      15        7     NaN      5.5   0.856075  2.168925       0\n",
       " 3  41.0  NaN      15       14   120.0      2.9   2.658720  0.821280       0\n",
       " 4  24.0  2.0       2        0    28.0     17.3   1.787436  3.056564       1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the functions to filter variables based on the given criteria\n",
    "\n",
    "def drop_low_variability_continuous(df, continuous_vars, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Drop continuous variables with a coefficient of variation less than the threshold.\n",
    "    \"\"\"\n",
    "    low_var_cols = [col for col in continuous_vars if df[col].std() / df[col].mean() < threshold]\n",
    "    df_filtered = df.drop(columns=low_var_cols)\n",
    "    return df_filtered, low_var_cols\n",
    "\n",
    "def drop_high_mode_categorical(df, categorical_vars, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Drop categorical variables where the mode category percentage is greater than the threshold.\n",
    "    \"\"\"\n",
    "    high_mode_cols = [col for col in categorical_vars if (df[col].value_counts().max() / len(df)) > threshold]\n",
    "    df_filtered = df.drop(columns=high_mode_cols)\n",
    "    return df_filtered, high_mode_cols\n",
    "\n",
    "def drop_high_unique_categorical(df, categorical_vars, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Drop categorical variables with a percentage of unique categories exceeding the threshold.\n",
    "    \"\"\"\n",
    "    high_unique_cols = [col for col in categorical_vars if (df[col].nunique() / len(df)) > threshold]\n",
    "    df_filtered = df.drop(columns=high_unique_cols)\n",
    "    return df_filtered, high_unique_cols\n",
    "\n",
    "\n",
    "# Apply filters\n",
    "data_filtered, low_var_cols = drop_low_variability_continuous(data, continuous_vars)\n",
    "data_filtered, high_mode_cols = drop_high_mode_categorical(data_filtered, categorical_vars)\n",
    "data_filtered, high_unique_cols = drop_high_unique_categorical(data_filtered, categorical_vars)\n",
    "\n",
    "# Check which columns were dropped\n",
    "dropped_columns = low_var_cols + high_mode_cols + high_unique_cols\n",
    "\n",
    "# Add the target variable back to the filtered dataframe\n",
    "filtered_df = data_filtered.copy()\n",
    "filtered_df['default'] = data['default']\n",
    "\n",
    "# Display the results\n",
    "dropped_columns, filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb533c",
   "metadata": {
    "papermill": {
     "duration": 0.003447,
     "end_time": "2024-05-22T11:22:04.880998",
     "exception": false,
     "start_time": "2024-05-22T11:22:04.877551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4216596,
     "sourceId": 7273365,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.624455,
   "end_time": "2024-05-22T11:22:05.405822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-22T11:22:00.781367",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
