{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/matinmahmoudi/from-scratch-modified-perceptron-using-oop?scriptVersionId=201715568\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"3b86f04e","metadata":{"execution":{"iopub.execute_input":"2024-10-17T14:45:41.106945Z","iopub.status.busy":"2024-10-17T14:45:41.10639Z","iopub.status.idle":"2024-10-17T14:45:41.129587Z","shell.execute_reply":"2024-10-17T14:45:41.12875Z"},"papermill":{"duration":0.02959,"end_time":"2024-10-17T14:45:41.131971","exception":false,"start_time":"2024-10-17T14:45:41.102381","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class Perceptron:\n","    \"\"\"\n","    Perceptron implemented from scratch using hinge loss and gradient descent.\n","    Loss and gradients are computed only for misclassified examples (negative margin).\n","    \"\"\"\n","    \n","    def __init__(self, in_features, epochs=1000, learning_rate=0.01, tolerance=1e-6, verbose=0, random_state=42):\n","        np.random.seed(random_state)\n","        self.w = np.random.randn(in_features + 1, 1)  # Merged bias into weights by adding 1 to features\n","        self.epochs = epochs  # Number of iterations\n","        self.learning_rate = learning_rate  # Learning rate for gradient descent\n","        self.tolerance = tolerance  # Tolerance for early stopping\n","        self.verbose = verbose  # Verbosity level\n","        self.loss_history_ = []  # History of loss values\n","        self.accuracy_history_ = []  # History of accuracy values\n","\n","    def _add_bias(self, X):\n","        \"\"\"\n","        Add a bias term to the input data by appending a column of ones.\n","        X_bias = [1, x1, x2, ... xn]\n","        \"\"\"\n","        return np.hstack([np.ones((X.shape[0], 1)), X])\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit the perceptron model using gradient descent.\n","        Updates weights only based on examples where y * y_hat < 0 (misclassified).\n","        \"\"\"\n","        X_bias = self._add_bias(X)  # Adding bias term to input features\n","        \n","        for epoch in range(self.epochs):\n","            y_hat = self.predict(X_bias)  # Raw predictions\n","            loss = self._loss(y, y_hat)  # Compute loss based only on misclassified points\n","            grad_w = self._grad(X_bias, y, y_hat)  # Compute gradients based on misclassified points\n","            \n","            self.w -= self.learning_rate * grad_w  # Gradient descent update\n","            self.loss_history_.append(loss)  # Track loss\n","            \n","            if self.verbose and epoch % 100 == 0:\n","                accuracy = self.score(X, y)\n","                print(f\"Epoch {epoch}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n","            \n","            # Early stopping based on tolerance\n","            if epoch > 0 and abs(self.loss_history_[-2] - self.loss_history_[-1]) < self.tolerance:\n","                if self.verbose:\n","                    print(f\"Early stopping at epoch {epoch}\")\n","                break\n","        \n","        self.plot_learning_curve()\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predict raw scores (without thresholding).\n","        Prediction: y_hat = Xw\n","        \"\"\"\n","        return X @ self.w\n","    \n","    def predict_class(self, X):\n","        \"\"\"\n","        Predict class labels by applying a threshold of 0 to the output.\n","        Class prediction: y_pred = 1 if Xw >= 0 else -1\n","        \"\"\"\n","        X_bias = self._add_bias(X)\n","        return np.where(self.predict(X_bias) >= 0, 1, -1)\n","    \n","    def score(self, X, y):\n","        \"\"\"\n","        Calculate the accuracy of the model.\n","        Accuracy: (Number of correct predictions) / (Total predictions)\n","        \"\"\"\n","        y_hat = self.predict(X)\n","        return self._accuracy(y, y_hat, t=0)\n","    \n","    def _accuracy(self, y, y_hat, t=0):\n","        \"\"\"\n","        Accuracy calculation with thresholding at t=0.\n","        y_pred = 1 if y_hat >= t else -1\n","        \"\"\"\n","        y_hat = np.where(y_hat < t, -1, 1)\n","        acc = np.sum(y == y_hat) / len(y)\n","        return acc\n","    \n","    def _loss(self, y, y_hat):\n","        \"\"\"\n","        Hinge loss:\n","        L = mean(max(0, -y * y_hat))  # Only misclassified points (where y * y_hat < 0) contribute to the loss.\n","        \"\"\"\n","        # Calculate loss only for misclassified examples\n","        return np.maximum(0, -y * y_hat).mean()\n","    \n","    def _grad(self, X, y, y_hat):\n","        \"\"\"\n","        Gradient of hinge loss:\n","        âˆ‡L = -mean(y * X) for misclassified points (where y * y_hat < 0)\n","        \"\"\"\n","        # Calculate gradients only for misclassified examples (y * y_hat < 0)\n","        mask = y * y_hat < 0  # Only misclassified points contribute to gradient\n","        grad_w = (-y[mask, np.newaxis] * X[mask]).mean(axis=0).reshape(self.w.shape)\n","        return grad_w\n","\n","    def plot_learning_curve(self):\n","        \"\"\"\n","        Plot the learning curve for the model's loss over epochs.\n","        \"\"\"\n","        if self.loss_history_:\n","            plt.plot(self.loss_history_)\n","            plt.title(\"Learning Curve\")\n","            plt.xlabel(\"Epochs\")\n","            plt.ylabel(\"Loss\")\n","            plt.grid(True)\n","            plt.show()\n","    \n","    def __repr__(self):\n","        return f'Perceptron(epochs={self.epochs}, learning_rate={self.learning_rate}, tolerance={self.tolerance})'\n"]},{"cell_type":"code","execution_count":null,"id":"08573a01","metadata":{"papermill":{"duration":0.001366,"end_time":"2024-10-17T14:45:41.135245","exception":false,"start_time":"2024-10-17T14:45:41.133879","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":2.976824,"end_time":"2024-10-17T14:45:41.456004","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-17T14:45:38.47918","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}